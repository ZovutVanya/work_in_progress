{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install matplotlib seaborn transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from numbers import Number\n",
    "from typing import Optional, Any\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _df_colors(val: Any):\n",
    "    '''Функция для более выделяющихся цветов в датафреймах'''\n",
    "    \n",
    "    if isinstance(val, bool) and val is False:\n",
    "        color = \"red\"\n",
    "    elif isinstance(val, bool) and val is True:\n",
    "        color = \"limegreen\"\n",
    "    elif isinstance(val, Number):\n",
    "        # color = \"gold\"\n",
    "        color = \"mediumspringgreen\"\n",
    "    else:\n",
    "        color = \"cornflowerblue\"\n",
    "    return \"color: %s\" % color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo2num = {'С': 1,\n",
    "           'О': 2,\n",
    "           'Н': 3,\n",
    "           'Ж': 4,\n",
    "           'У': 5,\n",
    "           'Р': 6,\n",
    "           'Г': 7,\n",
    "           'Б': 8,\n",
    "           'З': 9,\n",
    "           'В': 10}\n",
    "\n",
    "num2emo = {val: key for key, val in emo2num.items()}\n",
    "\n",
    "letter2emo = {\n",
    "\"Г\": \"грусть\",\n",
    "\"З\": \"злость\",\n",
    "\"Р\": \"радость\",\n",
    "\"У\": \"удивление\",\n",
    "\"В\": \"волнение\",\n",
    "\"Ж\": \"раздражение\",\n",
    "\"Н\": \"недовольство\",\n",
    "\"О\": \"обида\",\n",
    "\"Б\": \"обречённость\",\n",
    "\"С\": \"страх\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install catboost scikit-learn huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, roc_auc_score, roc_curve, RocCurveDisplay\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay#, multilabel_confusion_matrix\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_preds: ArrayLike, \n",
    "                  y: ArrayLike, \n",
    "                  y_probs: Optional[ArrayLike] = None\n",
    ") -> None:\n",
    "    print(f'MSE: {mean_squared_error(y_preds, y)}')\n",
    "    print(f\"Accuracy: {accuracy_score(y_preds, y)}\")\n",
    "    print(f\"F-score: {f1_score(y, y_preds, average='weighted')}\")\n",
    "    if y_probs is not None: \n",
    "        print(f\"ROC-AUC: {roc_auc_score(y, y_probs, multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_conf_matrx(y_real: ArrayLike, y_preds: ArrayLike, classes: ArrayLike, title: str=\"\") -> None:\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    ax.set_title(title)\n",
    "    cm_rfc = confusion_matrix(y_real, y_preds)\n",
    "    disp_rfc = ConfusionMatrixDisplay(cm_rfc, \n",
    "                                      display_labels=[letter2emo[num2emo[klas]] for klas in classes])\n",
    "    disp_rfc.plot(include_values=True, cmap=\"viridis\", ax=ax, colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_roc_curves(y_train: ArrayLike, y_test: ArrayLike, y_score: ArrayLike, classes: ArrayLike) -> None:\n",
    "    label_binarizer = LabelBinarizer().fit(y_train)\n",
    "    y_onehot_test = label_binarizer.transform(y_test)\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=5,\n",
    "                            nrows=2, \n",
    "                            figsize=(25, 10))\n",
    "    for class_of_interest, axis in zip(classes, axs.flatten()):\n",
    "        class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "        display = RocCurveDisplay.from_predictions(\n",
    "            y_onehot_test[:, class_id],\n",
    "            y_score[:, class_id],\n",
    "            name=f\"{letter2emo[num2emo[class_of_interest]]} vs the rest\",\n",
    "            color=\"darkorange\",\n",
    "            plot_chance_level=True,\n",
    "            ax=axis\n",
    "        )\n",
    "        _ = display.ax_.set(\n",
    "            xlabel=\"\",\n",
    "            ylabel=\"\",\n",
    "            # title=\"One-vs-Rest ROC curves\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importances(importances: ArrayLike, feature_names: ArrayLike, title: str, size=(6,6)) -> None:\n",
    "    importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "    sorted_importance = importances_df.sort_values(by='Importance', ascending=False)\n",
    "    sorted_importance = sorted_importance[sorted_importance != 0]\n",
    "    # fig, ax = plt.subplots(figsize=(10,6))\n",
    "    plt.figure(figsize=size)\n",
    "    plt.barh(sorted_importance['Feature'], sorted_importance['Importance'])\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUbert-base-cased-sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ivan\\.virtualenvs\\venv-jWtaTe96\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Ivan\\.virtualenvs\\venv-jWtaTe96\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ivan\\.cache\\huggingface\\hub\\models--DeepPavlov--rubert-base-cased-sentence. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task=\"feature-extraction\", model=\"DeepPavlov/rubert-base-cased-sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m      \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mType:\u001b[0m           FeatureExtractionPipeline\n",
      "\u001b[1;31mString form:\u001b[0m    <transformers.pipelines.feature_extraction.FeatureExtractionPipeline object at 0x000002697A2EDAD0>\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\ivan\\.virtualenvs\\venv-jwtate96\\lib\\site-packages\\transformers\\pipelines\\feature_extraction.py\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Feature extraction pipeline uses no model head. This pipeline extracts the hidden states from the base\n",
      "transformer, which can be used as features in downstream tasks.\n",
      "\n",
      "Example:\n",
      "\n",
      "```python\n",
      ">>> from transformers import pipeline\n",
      "\n",
      ">>> extractor = pipeline(model=\"google-bert/bert-base-uncased\", task=\"feature-extraction\")\n",
      ">>> result = extractor(\"This is a simple test.\", return_tensors=True)\n",
      ">>> result.shape  # This is a tensor of shape [1, sequence_lenth, hidden_dimension] representing the input string.\n",
      "torch.Size([1, 8, 768])\n",
      "```\n",
      "\n",
      "Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)\n",
      "\n",
      "This feature extraction pipeline can currently be loaded from [`pipeline`] using the task identifier:\n",
      "`\"feature-extraction\"`.\n",
      "\n",
      "All models may be used for this pipeline. See a list of all models, including community-contributed models on\n",
      "[huggingface.co/models](https://huggingface.co/models).\n",
      "\n",
      "Arguments:\n",
      "    model ([`PreTrainedModel`] or [`TFPreTrainedModel`]):\n",
      "        The model that will be used by the pipeline to make predictions. This needs to be a model inheriting from\n",
      "        [`PreTrainedModel`] for PyTorch and [`TFPreTrainedModel`] for TensorFlow.\n",
      "    tokenizer ([`PreTrainedTokenizer`]):\n",
      "        The tokenizer that will be used by the pipeline to encode data for the model. This object inherits from\n",
      "        [`PreTrainedTokenizer`].\n",
      "    modelcard (`str` or [`ModelCard`], *optional*):\n",
      "        Model card attributed to the model for this pipeline.\n",
      "    framework (`str`, *optional*):\n",
      "        The framework to use, either `\"pt\"` for PyTorch or `\"tf\"` for TensorFlow. The specified framework must be\n",
      "        installed.\n",
      "\n",
      "        If no framework is specified, will default to the one currently installed. If no framework is specified and\n",
      "        both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is\n",
      "        provided.\n",
      "    task (`str`, defaults to `\"\"`):\n",
      "        A task-identifier for the pipeline.\n",
      "    num_workers (`int`, *optional*, defaults to 8):\n",
      "        When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number of\n",
      "        workers to be used.\n",
      "    batch_size (`int`, *optional*, defaults to 1):\n",
      "        When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of\n",
      "        the batch to use, for inference this is not always beneficial, please read [Batching with\n",
      "        pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching) .\n",
      "    args_parser ([`~pipelines.ArgumentHandler`], *optional*):\n",
      "        Reference to the object in charge of parsing supplied pipeline parameters.\n",
      "    device (`int`, *optional*, defaults to -1):\n",
      "        Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, a positive will run the model on\n",
      "        the associated CUDA device id. You can pass native `torch.device` or a `str` too\n",
      "    torch_dtype (`str` or `torch.dtype`, *optional*):\n",
      "        Sent directly as `model_kwargs` (just a simpler shortcut) to use the available precision for this model\n",
      "        (`torch.float16`, `torch.bfloat16`, ... or `\"auto\"`)\n",
      "    tokenize_kwargs (`dict`, *optional*):\n",
      "            Additional dictionary of keyword arguments passed along to the tokenizer.\n",
      "    return_tensors (`bool`, *optional*):\n",
      "        If `True`, returns a tensor according to the specified framework, otherwise returns a list.\n",
      "\u001b[1;31mCall docstring:\u001b[0m\n",
      "Extract the features of the input(s).\n",
      "\n",
      "Args:\n",
      "    args (`str` or `List[str]`): One or several texts (or one list of texts) to get the features of.\n",
      "\n",
      "Return:\n",
      "    A nested list of `float`: The features computed by the model."
     ]
    }
   ],
   "source": [
    "pipe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purga = pipe(\"всякую пургу несет ломится в дом\", return_tensors=\"pt\")[0].numpy().mean(axis=0)\n",
    "print(type(purga))\n",
    "purga.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Ivan\\Desktop\\AI\\0_Dissertation\\work_in_progress\\basic_metrics_DF.csv\", sep=\",\", index_col=0)\n",
    "df = df[df.columns[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Primary Emotion</th>\n",
       "      <th>Emotion Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0107635181_00__00-channel-0-number-004_18310</td>\n",
       "      <td>С</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0107635181_00__00-channel-0-number-005_22100</td>\n",
       "      <td>С</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0107635181_00__00-channel-0-number-006_26690</td>\n",
       "      <td>С</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0107636961_00__00-channel-0-number-009_34800</td>\n",
       "      <td>С</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0107638181_00__00-channel-0-number-018_59400</td>\n",
       "      <td>С</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>0107694921_00__00-channel-0-number-022_81650</td>\n",
       "      <td>В</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>0107694921_00__00-channel-0-number-023_84640</td>\n",
       "      <td>В</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>0107695241_00__00-channel-0-number-008_23670</td>\n",
       "      <td>В</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>0107695481_00__00-channel-0-number-015_46040</td>\n",
       "      <td>В</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3571</th>\n",
       "      <td>0107695521_00__00-channel-0-number-004_10740</td>\n",
       "      <td>В</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               IDs Primary Emotion  \\\n",
       "0     0107635181_00__00-channel-0-number-004_18310               С   \n",
       "1     0107635181_00__00-channel-0-number-005_22100               С   \n",
       "2     0107635181_00__00-channel-0-number-006_26690               С   \n",
       "3     0107636961_00__00-channel-0-number-009_34800               С   \n",
       "4     0107638181_00__00-channel-0-number-018_59400               С   \n",
       "...                                            ...             ...   \n",
       "3567  0107694921_00__00-channel-0-number-022_81650               В   \n",
       "3568  0107694921_00__00-channel-0-number-023_84640               В   \n",
       "3569  0107695241_00__00-channel-0-number-008_23670               В   \n",
       "3570  0107695481_00__00-channel-0-number-015_46040               В   \n",
       "3571  0107695521_00__00-channel-0-number-004_10740               В   \n",
       "\n",
       "      Emotion Class  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "...             ...  \n",
       "3567             10  \n",
       "3568             10  \n",
       "3569             10  \n",
       "3570             10  \n",
       "3571             10  \n",
       "\n",
       "[3572 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Ivan\\Desktop\\AI\\0_Dissertation\\texts.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3572"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3572"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeds = pipe(texts, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeds = [emb[0].numpy().mean(axis=0) for emb in text_embeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "3572\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "print(type(text_embeds))\n",
    "print(len(text_embeds))\n",
    "print(text_embeds[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeds.insert(0, [f\"feat{i}\" for i in range(768)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat758</th>\n",
       "      <th>feat759</th>\n",
       "      <th>feat760</th>\n",
       "      <th>feat761</th>\n",
       "      <th>feat762</th>\n",
       "      <th>feat763</th>\n",
       "      <th>feat764</th>\n",
       "      <th>feat765</th>\n",
       "      <th>feat766</th>\n",
       "      <th>feat767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.336182</td>\n",
       "      <td>-0.978600</td>\n",
       "      <td>0.064792</td>\n",
       "      <td>0.014678</td>\n",
       "      <td>-0.489018</td>\n",
       "      <td>-1.092950</td>\n",
       "      <td>0.564810</td>\n",
       "      <td>-0.586239</td>\n",
       "      <td>0.680381</td>\n",
       "      <td>0.206242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226758</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.425370</td>\n",
       "      <td>-0.389919</td>\n",
       "      <td>-0.288666</td>\n",
       "      <td>0.664745</td>\n",
       "      <td>0.569422</td>\n",
       "      <td>-0.443074</td>\n",
       "      <td>-1.937111</td>\n",
       "      <td>0.295056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.615437</td>\n",
       "      <td>-1.193338</td>\n",
       "      <td>0.181830</td>\n",
       "      <td>0.332161</td>\n",
       "      <td>-1.090739</td>\n",
       "      <td>-0.921048</td>\n",
       "      <td>0.461458</td>\n",
       "      <td>-0.645808</td>\n",
       "      <td>0.313686</td>\n",
       "      <td>0.330984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296886</td>\n",
       "      <td>0.773741</td>\n",
       "      <td>-0.107751</td>\n",
       "      <td>-0.025881</td>\n",
       "      <td>0.470922</td>\n",
       "      <td>0.290819</td>\n",
       "      <td>-0.073808</td>\n",
       "      <td>0.106049</td>\n",
       "      <td>-0.419256</td>\n",
       "      <td>0.983564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.549098</td>\n",
       "      <td>-0.902954</td>\n",
       "      <td>0.268358</td>\n",
       "      <td>-0.542761</td>\n",
       "      <td>-0.687137</td>\n",
       "      <td>-0.715993</td>\n",
       "      <td>0.428710</td>\n",
       "      <td>0.179674</td>\n",
       "      <td>0.141197</td>\n",
       "      <td>-0.427280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094857</td>\n",
       "      <td>0.934849</td>\n",
       "      <td>0.453269</td>\n",
       "      <td>-0.040649</td>\n",
       "      <td>-0.102064</td>\n",
       "      <td>0.519733</td>\n",
       "      <td>-0.162834</td>\n",
       "      <td>0.556302</td>\n",
       "      <td>-0.898968</td>\n",
       "      <td>1.578456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.397106</td>\n",
       "      <td>-0.905729</td>\n",
       "      <td>0.059483</td>\n",
       "      <td>-0.190682</td>\n",
       "      <td>-0.921463</td>\n",
       "      <td>-1.212287</td>\n",
       "      <td>1.200263</td>\n",
       "      <td>-0.975856</td>\n",
       "      <td>0.639443</td>\n",
       "      <td>-0.471629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664801</td>\n",
       "      <td>0.796822</td>\n",
       "      <td>-0.120022</td>\n",
       "      <td>-0.789867</td>\n",
       "      <td>0.464255</td>\n",
       "      <td>0.445329</td>\n",
       "      <td>-0.349348</td>\n",
       "      <td>-0.415858</td>\n",
       "      <td>-1.530666</td>\n",
       "      <td>0.169327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.470222</td>\n",
       "      <td>-0.621110</td>\n",
       "      <td>0.139886</td>\n",
       "      <td>-0.192296</td>\n",
       "      <td>-1.096364</td>\n",
       "      <td>-0.867447</td>\n",
       "      <td>1.195484</td>\n",
       "      <td>-0.873055</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>-1.213681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408307</td>\n",
       "      <td>0.669286</td>\n",
       "      <td>0.491028</td>\n",
       "      <td>-0.699428</td>\n",
       "      <td>-0.341290</td>\n",
       "      <td>0.492713</td>\n",
       "      <td>-0.440385</td>\n",
       "      <td>-0.742058</td>\n",
       "      <td>-0.982369</td>\n",
       "      <td>1.175748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>-0.587985</td>\n",
       "      <td>-1.230122</td>\n",
       "      <td>0.012684</td>\n",
       "      <td>-0.541513</td>\n",
       "      <td>-1.019720</td>\n",
       "      <td>-0.959615</td>\n",
       "      <td>0.998319</td>\n",
       "      <td>-0.990592</td>\n",
       "      <td>0.188853</td>\n",
       "      <td>-0.477304</td>\n",
       "      <td>...</td>\n",
       "      <td>1.115508</td>\n",
       "      <td>0.822818</td>\n",
       "      <td>0.272012</td>\n",
       "      <td>-0.076765</td>\n",
       "      <td>-0.494952</td>\n",
       "      <td>0.580714</td>\n",
       "      <td>-0.211996</td>\n",
       "      <td>-0.580840</td>\n",
       "      <td>-1.035424</td>\n",
       "      <td>0.125643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>-0.388379</td>\n",
       "      <td>-1.336123</td>\n",
       "      <td>-0.097332</td>\n",
       "      <td>-0.725855</td>\n",
       "      <td>-0.879984</td>\n",
       "      <td>-0.204315</td>\n",
       "      <td>0.672689</td>\n",
       "      <td>-1.059146</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>-0.627051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713367</td>\n",
       "      <td>0.753234</td>\n",
       "      <td>-0.116164</td>\n",
       "      <td>0.106710</td>\n",
       "      <td>-0.459737</td>\n",
       "      <td>0.242026</td>\n",
       "      <td>-0.374719</td>\n",
       "      <td>-0.096708</td>\n",
       "      <td>-0.598987</td>\n",
       "      <td>1.642665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>-0.275345</td>\n",
       "      <td>-1.376961</td>\n",
       "      <td>0.654090</td>\n",
       "      <td>-1.514799</td>\n",
       "      <td>-0.630188</td>\n",
       "      <td>-0.979290</td>\n",
       "      <td>0.505319</td>\n",
       "      <td>1.257118</td>\n",
       "      <td>-0.071339</td>\n",
       "      <td>-0.044508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720569</td>\n",
       "      <td>0.839719</td>\n",
       "      <td>-0.581412</td>\n",
       "      <td>-0.073526</td>\n",
       "      <td>0.672445</td>\n",
       "      <td>-0.143098</td>\n",
       "      <td>0.401223</td>\n",
       "      <td>0.475732</td>\n",
       "      <td>-0.383431</td>\n",
       "      <td>0.987155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>-0.606162</td>\n",
       "      <td>-1.226191</td>\n",
       "      <td>-0.472120</td>\n",
       "      <td>-0.075325</td>\n",
       "      <td>-1.178378</td>\n",
       "      <td>-0.782325</td>\n",
       "      <td>0.681779</td>\n",
       "      <td>-0.522094</td>\n",
       "      <td>0.970932</td>\n",
       "      <td>-0.628848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485743</td>\n",
       "      <td>0.640106</td>\n",
       "      <td>0.282853</td>\n",
       "      <td>-0.161575</td>\n",
       "      <td>-0.002824</td>\n",
       "      <td>0.849257</td>\n",
       "      <td>-0.244747</td>\n",
       "      <td>-0.207271</td>\n",
       "      <td>-1.096731</td>\n",
       "      <td>0.073357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3571</th>\n",
       "      <td>0.072091</td>\n",
       "      <td>-1.006570</td>\n",
       "      <td>-0.115790</td>\n",
       "      <td>-0.647152</td>\n",
       "      <td>-0.771450</td>\n",
       "      <td>-1.419349</td>\n",
       "      <td>0.919379</td>\n",
       "      <td>-0.354618</td>\n",
       "      <td>0.172215</td>\n",
       "      <td>0.116845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128548</td>\n",
       "      <td>0.827746</td>\n",
       "      <td>-0.387195</td>\n",
       "      <td>-0.201179</td>\n",
       "      <td>-0.200888</td>\n",
       "      <td>0.387101</td>\n",
       "      <td>0.147380</td>\n",
       "      <td>-0.287610</td>\n",
       "      <td>-1.488193</td>\n",
       "      <td>1.001735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3572 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feat0     feat1     feat2     feat3     feat4     feat5     feat6  \\\n",
       "0    -0.336182 -0.978600  0.064792  0.014678 -0.489018 -1.092950  0.564810   \n",
       "1    -0.615437 -1.193338  0.181830  0.332161 -1.090739 -0.921048  0.461458   \n",
       "2    -0.549098 -0.902954  0.268358 -0.542761 -0.687137 -0.715993  0.428710   \n",
       "3    -0.397106 -0.905729  0.059483 -0.190682 -0.921463 -1.212287  1.200263   \n",
       "4    -0.470222 -0.621110  0.139886 -0.192296 -1.096364 -0.867447  1.195484   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3567 -0.587985 -1.230122  0.012684 -0.541513 -1.019720 -0.959615  0.998319   \n",
       "3568 -0.388379 -1.336123 -0.097332 -0.725855 -0.879984 -0.204315  0.672689   \n",
       "3569 -0.275345 -1.376961  0.654090 -1.514799 -0.630188 -0.979290  0.505319   \n",
       "3570 -0.606162 -1.226191 -0.472120 -0.075325 -1.178378 -0.782325  0.681779   \n",
       "3571  0.072091 -1.006570 -0.115790 -0.647152 -0.771450 -1.419349  0.919379   \n",
       "\n",
       "         feat7     feat8     feat9  ...   feat758   feat759   feat760  \\\n",
       "0    -0.586239  0.680381  0.206242  ... -0.226758  0.625000  0.425370   \n",
       "1    -0.645808  0.313686  0.330984  ...  0.296886  0.773741 -0.107751   \n",
       "2     0.179674  0.141197 -0.427280  ... -0.094857  0.934849  0.453269   \n",
       "3    -0.975856  0.639443 -0.471629  ...  0.664801  0.796822 -0.120022   \n",
       "4    -0.873055  0.079130 -1.213681  ...  0.408307  0.669286  0.491028   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3567 -0.990592  0.188853 -0.477304  ...  1.115508  0.822818  0.272012   \n",
       "3568 -1.059146  0.003165 -0.627051  ...  0.713367  0.753234 -0.116164   \n",
       "3569  1.257118 -0.071339 -0.044508  ... -0.720569  0.839719 -0.581412   \n",
       "3570 -0.522094  0.970932 -0.628848  ...  0.485743  0.640106  0.282853   \n",
       "3571 -0.354618  0.172215  0.116845  ... -0.128548  0.827746 -0.387195   \n",
       "\n",
       "       feat761   feat762   feat763   feat764   feat765   feat766   feat767  \n",
       "0    -0.389919 -0.288666  0.664745  0.569422 -0.443074 -1.937111  0.295056  \n",
       "1    -0.025881  0.470922  0.290819 -0.073808  0.106049 -0.419256  0.983564  \n",
       "2    -0.040649 -0.102064  0.519733 -0.162834  0.556302 -0.898968  1.578456  \n",
       "3    -0.789867  0.464255  0.445329 -0.349348 -0.415858 -1.530666  0.169327  \n",
       "4    -0.699428 -0.341290  0.492713 -0.440385 -0.742058 -0.982369  1.175748  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3567 -0.076765 -0.494952  0.580714 -0.211996 -0.580840 -1.035424  0.125643  \n",
       "3568  0.106710 -0.459737  0.242026 -0.374719 -0.096708 -0.598987  1.642665  \n",
       "3569 -0.073526  0.672445 -0.143098  0.401223  0.475732 -0.383431  0.987155  \n",
       "3570 -0.161575 -0.002824  0.849257 -0.244747 -0.207271 -1.096731  0.073357  \n",
       "3571 -0.201179 -0.200888  0.387101  0.147380 -0.287610 -1.488193  1.001735  \n",
       "\n",
       "[3572 rows x 768 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeds_df = pd.DataFrame(text_embeds[1:], columns=text_embeds[0])\n",
    "text_embeds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Primary Emotion</th>\n",
       "      <th>Emotion Class</th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>...</th>\n",
       "      <th>feat758</th>\n",
       "      <th>feat759</th>\n",
       "      <th>feat760</th>\n",
       "      <th>feat761</th>\n",
       "      <th>feat762</th>\n",
       "      <th>feat763</th>\n",
       "      <th>feat764</th>\n",
       "      <th>feat765</th>\n",
       "      <th>feat766</th>\n",
       "      <th>feat767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0107635181_00__00-channel-0-number-004_18310</td>\n",
       "      <td>С</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.336182</td>\n",
       "      <td>-0.978600</td>\n",
       "      <td>0.064792</td>\n",
       "      <td>0.014678</td>\n",
       "      <td>-0.489018</td>\n",
       "      <td>-1.092950</td>\n",
       "      <td>0.564810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226758</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.425370</td>\n",
       "      <td>-0.389919</td>\n",
       "      <td>-0.288666</td>\n",
       "      <td>0.664745</td>\n",
       "      <td>0.569422</td>\n",
       "      <td>-0.443074</td>\n",
       "      <td>-1.937111</td>\n",
       "      <td>0.295056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0107635181_00__00-channel-0-number-005_22100</td>\n",
       "      <td>С</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.615437</td>\n",
       "      <td>-1.193338</td>\n",
       "      <td>0.181830</td>\n",
       "      <td>0.332161</td>\n",
       "      <td>-1.090739</td>\n",
       "      <td>-0.921048</td>\n",
       "      <td>0.461458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296886</td>\n",
       "      <td>0.773741</td>\n",
       "      <td>-0.107751</td>\n",
       "      <td>-0.025881</td>\n",
       "      <td>0.470922</td>\n",
       "      <td>0.290819</td>\n",
       "      <td>-0.073808</td>\n",
       "      <td>0.106049</td>\n",
       "      <td>-0.419256</td>\n",
       "      <td>0.983564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0107635181_00__00-channel-0-number-006_26690</td>\n",
       "      <td>С</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.549098</td>\n",
       "      <td>-0.902954</td>\n",
       "      <td>0.268358</td>\n",
       "      <td>-0.542761</td>\n",
       "      <td>-0.687137</td>\n",
       "      <td>-0.715993</td>\n",
       "      <td>0.428710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094857</td>\n",
       "      <td>0.934849</td>\n",
       "      <td>0.453269</td>\n",
       "      <td>-0.040649</td>\n",
       "      <td>-0.102064</td>\n",
       "      <td>0.519733</td>\n",
       "      <td>-0.162834</td>\n",
       "      <td>0.556302</td>\n",
       "      <td>-0.898968</td>\n",
       "      <td>1.578456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0107636961_00__00-channel-0-number-009_34800</td>\n",
       "      <td>С</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.397106</td>\n",
       "      <td>-0.905729</td>\n",
       "      <td>0.059483</td>\n",
       "      <td>-0.190682</td>\n",
       "      <td>-0.921463</td>\n",
       "      <td>-1.212287</td>\n",
       "      <td>1.200263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664801</td>\n",
       "      <td>0.796822</td>\n",
       "      <td>-0.120022</td>\n",
       "      <td>-0.789867</td>\n",
       "      <td>0.464255</td>\n",
       "      <td>0.445329</td>\n",
       "      <td>-0.349348</td>\n",
       "      <td>-0.415858</td>\n",
       "      <td>-1.530666</td>\n",
       "      <td>0.169327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0107638181_00__00-channel-0-number-018_59400</td>\n",
       "      <td>С</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.470222</td>\n",
       "      <td>-0.621110</td>\n",
       "      <td>0.139886</td>\n",
       "      <td>-0.192296</td>\n",
       "      <td>-1.096364</td>\n",
       "      <td>-0.867447</td>\n",
       "      <td>1.195484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408307</td>\n",
       "      <td>0.669286</td>\n",
       "      <td>0.491028</td>\n",
       "      <td>-0.699428</td>\n",
       "      <td>-0.341290</td>\n",
       "      <td>0.492713</td>\n",
       "      <td>-0.440385</td>\n",
       "      <td>-0.742058</td>\n",
       "      <td>-0.982369</td>\n",
       "      <td>1.175748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>0107694921_00__00-channel-0-number-022_81650</td>\n",
       "      <td>В</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.587985</td>\n",
       "      <td>-1.230122</td>\n",
       "      <td>0.012684</td>\n",
       "      <td>-0.541513</td>\n",
       "      <td>-1.019720</td>\n",
       "      <td>-0.959615</td>\n",
       "      <td>0.998319</td>\n",
       "      <td>...</td>\n",
       "      <td>1.115508</td>\n",
       "      <td>0.822818</td>\n",
       "      <td>0.272012</td>\n",
       "      <td>-0.076765</td>\n",
       "      <td>-0.494952</td>\n",
       "      <td>0.580714</td>\n",
       "      <td>-0.211996</td>\n",
       "      <td>-0.580840</td>\n",
       "      <td>-1.035424</td>\n",
       "      <td>0.125643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>0107694921_00__00-channel-0-number-023_84640</td>\n",
       "      <td>В</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.388379</td>\n",
       "      <td>-1.336123</td>\n",
       "      <td>-0.097332</td>\n",
       "      <td>-0.725855</td>\n",
       "      <td>-0.879984</td>\n",
       "      <td>-0.204315</td>\n",
       "      <td>0.672689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713367</td>\n",
       "      <td>0.753234</td>\n",
       "      <td>-0.116164</td>\n",
       "      <td>0.106710</td>\n",
       "      <td>-0.459737</td>\n",
       "      <td>0.242026</td>\n",
       "      <td>-0.374719</td>\n",
       "      <td>-0.096708</td>\n",
       "      <td>-0.598987</td>\n",
       "      <td>1.642665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>0107695241_00__00-channel-0-number-008_23670</td>\n",
       "      <td>В</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.275345</td>\n",
       "      <td>-1.376961</td>\n",
       "      <td>0.654090</td>\n",
       "      <td>-1.514799</td>\n",
       "      <td>-0.630188</td>\n",
       "      <td>-0.979290</td>\n",
       "      <td>0.505319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720569</td>\n",
       "      <td>0.839719</td>\n",
       "      <td>-0.581412</td>\n",
       "      <td>-0.073526</td>\n",
       "      <td>0.672445</td>\n",
       "      <td>-0.143098</td>\n",
       "      <td>0.401223</td>\n",
       "      <td>0.475732</td>\n",
       "      <td>-0.383431</td>\n",
       "      <td>0.987155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>0107695481_00__00-channel-0-number-015_46040</td>\n",
       "      <td>В</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.606162</td>\n",
       "      <td>-1.226191</td>\n",
       "      <td>-0.472120</td>\n",
       "      <td>-0.075325</td>\n",
       "      <td>-1.178378</td>\n",
       "      <td>-0.782325</td>\n",
       "      <td>0.681779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485743</td>\n",
       "      <td>0.640106</td>\n",
       "      <td>0.282853</td>\n",
       "      <td>-0.161575</td>\n",
       "      <td>-0.002824</td>\n",
       "      <td>0.849257</td>\n",
       "      <td>-0.244747</td>\n",
       "      <td>-0.207271</td>\n",
       "      <td>-1.096731</td>\n",
       "      <td>0.073357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3571</th>\n",
       "      <td>0107695521_00__00-channel-0-number-004_10740</td>\n",
       "      <td>В</td>\n",
       "      <td>10</td>\n",
       "      <td>0.072091</td>\n",
       "      <td>-1.006570</td>\n",
       "      <td>-0.115790</td>\n",
       "      <td>-0.647152</td>\n",
       "      <td>-0.771450</td>\n",
       "      <td>-1.419349</td>\n",
       "      <td>0.919379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128548</td>\n",
       "      <td>0.827746</td>\n",
       "      <td>-0.387195</td>\n",
       "      <td>-0.201179</td>\n",
       "      <td>-0.200888</td>\n",
       "      <td>0.387101</td>\n",
       "      <td>0.147380</td>\n",
       "      <td>-0.287610</td>\n",
       "      <td>-1.488193</td>\n",
       "      <td>1.001735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3572 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               IDs Primary Emotion  \\\n",
       "0     0107635181_00__00-channel-0-number-004_18310               С   \n",
       "1     0107635181_00__00-channel-0-number-005_22100               С   \n",
       "2     0107635181_00__00-channel-0-number-006_26690               С   \n",
       "3     0107636961_00__00-channel-0-number-009_34800               С   \n",
       "4     0107638181_00__00-channel-0-number-018_59400               С   \n",
       "...                                            ...             ...   \n",
       "3567  0107694921_00__00-channel-0-number-022_81650               В   \n",
       "3568  0107694921_00__00-channel-0-number-023_84640               В   \n",
       "3569  0107695241_00__00-channel-0-number-008_23670               В   \n",
       "3570  0107695481_00__00-channel-0-number-015_46040               В   \n",
       "3571  0107695521_00__00-channel-0-number-004_10740               В   \n",
       "\n",
       "      Emotion Class     feat0     feat1     feat2     feat3     feat4  \\\n",
       "0                 1 -0.336182 -0.978600  0.064792  0.014678 -0.489018   \n",
       "1                 1 -0.615437 -1.193338  0.181830  0.332161 -1.090739   \n",
       "2                 1 -0.549098 -0.902954  0.268358 -0.542761 -0.687137   \n",
       "3                 1 -0.397106 -0.905729  0.059483 -0.190682 -0.921463   \n",
       "4                 1 -0.470222 -0.621110  0.139886 -0.192296 -1.096364   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "3567             10 -0.587985 -1.230122  0.012684 -0.541513 -1.019720   \n",
       "3568             10 -0.388379 -1.336123 -0.097332 -0.725855 -0.879984   \n",
       "3569             10 -0.275345 -1.376961  0.654090 -1.514799 -0.630188   \n",
       "3570             10 -0.606162 -1.226191 -0.472120 -0.075325 -1.178378   \n",
       "3571             10  0.072091 -1.006570 -0.115790 -0.647152 -0.771450   \n",
       "\n",
       "         feat5     feat6  ...   feat758   feat759   feat760   feat761  \\\n",
       "0    -1.092950  0.564810  ... -0.226758  0.625000  0.425370 -0.389919   \n",
       "1    -0.921048  0.461458  ...  0.296886  0.773741 -0.107751 -0.025881   \n",
       "2    -0.715993  0.428710  ... -0.094857  0.934849  0.453269 -0.040649   \n",
       "3    -1.212287  1.200263  ...  0.664801  0.796822 -0.120022 -0.789867   \n",
       "4    -0.867447  1.195484  ...  0.408307  0.669286  0.491028 -0.699428   \n",
       "...        ...       ...  ...       ...       ...       ...       ...   \n",
       "3567 -0.959615  0.998319  ...  1.115508  0.822818  0.272012 -0.076765   \n",
       "3568 -0.204315  0.672689  ...  0.713367  0.753234 -0.116164  0.106710   \n",
       "3569 -0.979290  0.505319  ... -0.720569  0.839719 -0.581412 -0.073526   \n",
       "3570 -0.782325  0.681779  ...  0.485743  0.640106  0.282853 -0.161575   \n",
       "3571 -1.419349  0.919379  ... -0.128548  0.827746 -0.387195 -0.201179   \n",
       "\n",
       "       feat762   feat763   feat764   feat765   feat766   feat767  \n",
       "0    -0.288666  0.664745  0.569422 -0.443074 -1.937111  0.295056  \n",
       "1     0.470922  0.290819 -0.073808  0.106049 -0.419256  0.983564  \n",
       "2    -0.102064  0.519733 -0.162834  0.556302 -0.898968  1.578456  \n",
       "3     0.464255  0.445329 -0.349348 -0.415858 -1.530666  0.169327  \n",
       "4    -0.341290  0.492713 -0.440385 -0.742058 -0.982369  1.175748  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "3567 -0.494952  0.580714 -0.211996 -0.580840 -1.035424  0.125643  \n",
       "3568 -0.459737  0.242026 -0.374719 -0.096708 -0.598987  1.642665  \n",
       "3569  0.672445 -0.143098  0.401223  0.475732 -0.383431  0.987155  \n",
       "3570 -0.002824  0.849257 -0.244747 -0.207271 -1.096731  0.073357  \n",
       "3571 -0.200888  0.387101  0.147380 -0.287610 -1.488193  1.001735  \n",
       "\n",
       "[3572 rows x 771 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF = pd.merge(df, text_embeds_df, left_index=True, right_index=True)\n",
    "newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3498, 771)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF = newDF.drop_duplicates(subset=[\"IDs\"])\n",
    "newDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newDF[newDF.columns[3:]], \n",
    "                                                    newDF[\"Emotion Class\"], \n",
    "                                                    test_size=0.1, # данных не так много, берём максимум на обучение \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "MSE: 18.68\n",
      "Accuracy: 0.45714285714285713\n",
      "F-score: 0.3966671837838665\n",
      "ROC-AUC: 0.6220438326474046\n",
      "\n",
      "Train:\n",
      "MSE: 11.208068614993646\n",
      "Accuracy: 0.6289707750952986\n",
      "F-score: 0.5752078448906632\n",
      "ROC-AUC: 0.803573951166052\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(criterion=\"gini\", \n",
    "                             splitter=\"best\", \n",
    "                             max_depth = 7, \n",
    "                            #  min_samples_split = 2, \n",
    "                            #  min_samples_leaf = 1, \n",
    "                            #  min_weight_fraction_leaf = 0, \n",
    "                            #  max_features = \"sqrt\", \n",
    "                             random_state = 42, \n",
    "                            #  max_leaf_nodes = None, \n",
    "                            #  min_impurity_decrease = 0, \n",
    "                            #  class_weight = None, \n",
    "                             ccp_alpha = 0)\n",
    "dtc.fit(X=X_train, y=y_train)\n",
    "\n",
    "print(\"Test:\")\n",
    "print_metrics(dtc.predict(X_test), y_test, dtc.predict_proba(X_test))\n",
    "\n",
    "print(\"\\nTrain:\")\n",
    "print_metrics(dtc.predict(X_train), y_train, dtc.predict_proba(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "MSE: 20.437142857142856\n",
      "Accuracy: 0.44285714285714284\n",
      "F-score: 0.30133075266368753\n",
      "ROC-AUC: 0.6724575129117313\n",
      "\n",
      "Train:\n",
      "MSE: 5.082909783989835\n",
      "Accuracy: 0.8116264294790343\n",
      "F-score: 0.7800748043361274\n",
      "ROC-AUC: 0.9997953950775598\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=1000,\n",
    "                             criterion=\"gini\",\n",
    "                             max_depth=10, \n",
    "                             min_samples_split=2,\n",
    "                             min_samples_leaf=1,\n",
    "                             min_weight_fraction_leaf=0,\n",
    "                             max_features=\"sqrt\",\n",
    "                             max_leaf_nodes=None,\n",
    "                             min_impurity_decrease=0,\n",
    "                             bootstrap=True,\n",
    "                             oob_score=False,\n",
    "                             n_jobs=-1,\n",
    "                             random_state=42,\n",
    "                             verbose=0,\n",
    "                             warm_start=False,\n",
    "                             class_weight=None,\n",
    "                             ccp_alpha=0,\n",
    "                             max_samples=None\n",
    ")\n",
    "rfc.fit(X=X_train, y=y_train)\n",
    "\n",
    "print(\"Test:\")\n",
    "print_metrics(rfc.predict(X_test), y_test, rfc.predict_proba(X_test))\n",
    "print(\"\\nTrain:\")\n",
    "print_metrics(rfc.predict(X_train), y_train, rfc.predict_proba(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.083892\n",
      "0:\tlearn: 2.1624286\ttotal: 1.71s\tremaining: 28m 32s\n",
      "1:\tlearn: 2.0530065\ttotal: 3.07s\tremaining: 25m 31s\n",
      "2:\tlearn: 1.9609373\ttotal: 4.27s\tremaining: 23m 40s\n",
      "3:\tlearn: 1.8887894\ttotal: 5.52s\tremaining: 22m 55s\n",
      "4:\tlearn: 1.8264092\ttotal: 6.72s\tremaining: 22m 17s\n",
      "5:\tlearn: 1.7735616\ttotal: 8s\tremaining: 22m 5s\n",
      "6:\tlearn: 1.7306389\ttotal: 9.25s\tremaining: 21m 52s\n",
      "7:\tlearn: 1.6943722\ttotal: 10.5s\tremaining: 21m 44s\n",
      "8:\tlearn: 1.6616364\ttotal: 12s\tremaining: 22m 3s\n",
      "9:\tlearn: 1.6346825\ttotal: 13.5s\tremaining: 22m 19s\n",
      "10:\tlearn: 1.6099490\ttotal: 15s\tremaining: 22m 32s\n",
      "11:\tlearn: 1.5864081\ttotal: 16.6s\tremaining: 22m 50s\n",
      "12:\tlearn: 1.5662091\ttotal: 18.2s\tremaining: 23m 2s\n",
      "13:\tlearn: 1.5480153\ttotal: 19.7s\tremaining: 23m 7s\n",
      "14:\tlearn: 1.5300618\ttotal: 21.2s\tremaining: 23m 11s\n",
      "15:\tlearn: 1.5143672\ttotal: 22.7s\tremaining: 23m 13s\n",
      "16:\tlearn: 1.4990474\ttotal: 24.1s\tremaining: 23m 15s\n",
      "17:\tlearn: 1.4870485\ttotal: 25.6s\tremaining: 23m 15s\n",
      "18:\tlearn: 1.4736387\ttotal: 27s\tremaining: 23m 15s\n",
      "19:\tlearn: 1.4624803\ttotal: 28.5s\tremaining: 23m 14s\n",
      "20:\tlearn: 1.4516030\ttotal: 30s\tremaining: 23m 16s\n",
      "21:\tlearn: 1.4405860\ttotal: 31.4s\tremaining: 23m 16s\n",
      "22:\tlearn: 1.4301777\ttotal: 32.9s\tremaining: 23m 17s\n",
      "23:\tlearn: 1.4212275\ttotal: 34.3s\tremaining: 23m 15s\n",
      "24:\tlearn: 1.4117721\ttotal: 35.8s\tremaining: 23m 17s\n",
      "25:\tlearn: 1.4027648\ttotal: 37.3s\tremaining: 23m 17s\n",
      "26:\tlearn: 1.3941645\ttotal: 38.8s\tremaining: 23m 17s\n",
      "27:\tlearn: 1.3864477\ttotal: 40.3s\tremaining: 23m 17s\n",
      "28:\tlearn: 1.3784610\ttotal: 41.7s\tremaining: 23m 17s\n",
      "29:\tlearn: 1.3722352\ttotal: 43.2s\tremaining: 23m 17s\n",
      "30:\tlearn: 1.3646681\ttotal: 44.7s\tremaining: 23m 16s\n",
      "31:\tlearn: 1.3582056\ttotal: 46.1s\tremaining: 23m 14s\n",
      "32:\tlearn: 1.3521342\ttotal: 47.6s\tremaining: 23m 13s\n",
      "33:\tlearn: 1.3456437\ttotal: 49.1s\tremaining: 23m 14s\n",
      "34:\tlearn: 1.3400040\ttotal: 50.5s\tremaining: 23m 11s\n",
      "35:\tlearn: 1.3344411\ttotal: 52s\tremaining: 23m 12s\n",
      "36:\tlearn: 1.3267133\ttotal: 53.4s\tremaining: 23m 11s\n",
      "37:\tlearn: 1.3212260\ttotal: 54.9s\tremaining: 23m 10s\n",
      "38:\tlearn: 1.3146776\ttotal: 56.4s\tremaining: 23m 9s\n",
      "39:\tlearn: 1.3100060\ttotal: 57.8s\tremaining: 23m 8s\n",
      "40:\tlearn: 1.3043532\ttotal: 59.3s\tremaining: 23m 7s\n",
      "41:\tlearn: 1.2991300\ttotal: 1m\tremaining: 23m 5s\n",
      "42:\tlearn: 1.2949304\ttotal: 1m 2s\tremaining: 23m 7s\n",
      "43:\tlearn: 1.2901044\ttotal: 1m 3s\tremaining: 23m 5s\n",
      "44:\tlearn: 1.2847270\ttotal: 1m 5s\tremaining: 23m 5s\n",
      "45:\tlearn: 1.2790146\ttotal: 1m 6s\tremaining: 23m 3s\n",
      "46:\tlearn: 1.2741056\ttotal: 1m 8s\tremaining: 23m 2s\n",
      "47:\tlearn: 1.2680770\ttotal: 1m 9s\tremaining: 23m 1s\n",
      "48:\tlearn: 1.2638369\ttotal: 1m 11s\tremaining: 23m\n",
      "49:\tlearn: 1.2589525\ttotal: 1m 12s\tremaining: 22m 58s\n",
      "50:\tlearn: 1.2550960\ttotal: 1m 14s\tremaining: 22m 57s\n",
      "51:\tlearn: 1.2497860\ttotal: 1m 15s\tremaining: 22m 55s\n",
      "52:\tlearn: 1.2451862\ttotal: 1m 16s\tremaining: 22m 54s\n",
      "53:\tlearn: 1.2407835\ttotal: 1m 18s\tremaining: 22m 53s\n",
      "54:\tlearn: 1.2359383\ttotal: 1m 19s\tremaining: 22m 52s\n",
      "55:\tlearn: 1.2296569\ttotal: 1m 21s\tremaining: 22m 51s\n",
      "56:\tlearn: 1.2266714\ttotal: 1m 22s\tremaining: 22m 49s\n",
      "57:\tlearn: 1.2220274\ttotal: 1m 24s\tremaining: 22m 48s\n",
      "58:\tlearn: 1.2176134\ttotal: 1m 25s\tremaining: 22m 47s\n",
      "59:\tlearn: 1.2128508\ttotal: 1m 27s\tremaining: 22m 46s\n",
      "60:\tlearn: 1.2083486\ttotal: 1m 28s\tremaining: 22m 45s\n",
      "61:\tlearn: 1.2039690\ttotal: 1m 30s\tremaining: 22m 44s\n",
      "62:\tlearn: 1.1997059\ttotal: 1m 31s\tremaining: 22m 42s\n",
      "63:\tlearn: 1.1957509\ttotal: 1m 33s\tremaining: 22m 41s\n",
      "64:\tlearn: 1.1918993\ttotal: 1m 34s\tremaining: 22m 39s\n",
      "65:\tlearn: 1.1870298\ttotal: 1m 36s\tremaining: 22m 39s\n",
      "66:\tlearn: 1.1841371\ttotal: 1m 37s\tremaining: 22m 37s\n",
      "67:\tlearn: 1.1797083\ttotal: 1m 38s\tremaining: 22m 36s\n",
      "68:\tlearn: 1.1761747\ttotal: 1m 40s\tremaining: 22m 34s\n",
      "69:\tlearn: 1.1717032\ttotal: 1m 41s\tremaining: 22m 33s\n",
      "70:\tlearn: 1.1690290\ttotal: 1m 43s\tremaining: 22m 31s\n",
      "71:\tlearn: 1.1638737\ttotal: 1m 44s\tremaining: 22m 30s\n",
      "72:\tlearn: 1.1612677\ttotal: 1m 46s\tremaining: 22m 28s\n",
      "73:\tlearn: 1.1569553\ttotal: 1m 47s\tremaining: 22m 31s\n",
      "74:\tlearn: 1.1528304\ttotal: 1m 49s\tremaining: 22m 30s\n",
      "75:\tlearn: 1.1483265\ttotal: 1m 50s\tremaining: 22m 28s\n",
      "76:\tlearn: 1.1438670\ttotal: 1m 52s\tremaining: 22m 27s\n",
      "77:\tlearn: 1.1404219\ttotal: 1m 53s\tremaining: 22m 25s\n",
      "78:\tlearn: 1.1367893\ttotal: 1m 55s\tremaining: 22m 24s\n",
      "79:\tlearn: 1.1333464\ttotal: 1m 56s\tremaining: 22m 22s\n",
      "80:\tlearn: 1.1298070\ttotal: 1m 58s\tremaining: 22m 21s\n",
      "81:\tlearn: 1.1263577\ttotal: 1m 59s\tremaining: 22m 19s\n",
      "82:\tlearn: 1.1232875\ttotal: 2m 1s\tremaining: 22m 17s\n",
      "83:\tlearn: 1.1200589\ttotal: 2m 2s\tremaining: 22m 16s\n",
      "84:\tlearn: 1.1164992\ttotal: 2m 3s\tremaining: 22m 14s\n",
      "85:\tlearn: 1.1124403\ttotal: 2m 5s\tremaining: 22m 13s\n",
      "86:\tlearn: 1.1086970\ttotal: 2m 6s\tremaining: 22m 11s\n",
      "87:\tlearn: 1.1058602\ttotal: 2m 8s\tremaining: 22m 10s\n",
      "88:\tlearn: 1.1016342\ttotal: 2m 9s\tremaining: 22m 8s\n",
      "89:\tlearn: 1.0974699\ttotal: 2m 11s\tremaining: 22m 7s\n",
      "90:\tlearn: 1.0941838\ttotal: 2m 12s\tremaining: 22m 6s\n",
      "91:\tlearn: 1.0900212\ttotal: 2m 14s\tremaining: 22m 5s\n",
      "92:\tlearn: 1.0855342\ttotal: 2m 15s\tremaining: 22m 3s\n",
      "93:\tlearn: 1.0806891\ttotal: 2m 17s\tremaining: 22m 2s\n",
      "94:\tlearn: 1.0755958\ttotal: 2m 18s\tremaining: 22m\n",
      "95:\tlearn: 1.0715425\ttotal: 2m 20s\tremaining: 21m 59s\n",
      "96:\tlearn: 1.0683120\ttotal: 2m 21s\tremaining: 21m 57s\n",
      "97:\tlearn: 1.0651360\ttotal: 2m 23s\tremaining: 21m 56s\n",
      "98:\tlearn: 1.0615107\ttotal: 2m 24s\tremaining: 21m 55s\n",
      "99:\tlearn: 1.0585790\ttotal: 2m 25s\tremaining: 21m 53s\n",
      "100:\tlearn: 1.0541335\ttotal: 2m 27s\tremaining: 21m 52s\n",
      "101:\tlearn: 1.0498938\ttotal: 2m 28s\tremaining: 21m 51s\n",
      "102:\tlearn: 1.0468791\ttotal: 2m 30s\tremaining: 21m 50s\n",
      "103:\tlearn: 1.0434006\ttotal: 2m 31s\tremaining: 21m 48s\n",
      "104:\tlearn: 1.0398491\ttotal: 2m 33s\tremaining: 21m 47s\n",
      "105:\tlearn: 1.0368125\ttotal: 2m 34s\tremaining: 21m 45s\n",
      "106:\tlearn: 1.0349141\ttotal: 2m 36s\tremaining: 21m 44s\n",
      "107:\tlearn: 1.0311532\ttotal: 2m 37s\tremaining: 21m 42s\n",
      "108:\tlearn: 1.0277484\ttotal: 2m 39s\tremaining: 21m 41s\n",
      "109:\tlearn: 1.0239853\ttotal: 2m 40s\tremaining: 21m 40s\n",
      "110:\tlearn: 1.0208421\ttotal: 2m 42s\tremaining: 21m 38s\n",
      "111:\tlearn: 1.0174527\ttotal: 2m 43s\tremaining: 21m 37s\n",
      "112:\tlearn: 1.0152826\ttotal: 2m 45s\tremaining: 21m 35s\n",
      "113:\tlearn: 1.0125178\ttotal: 2m 46s\tremaining: 21m 33s\n",
      "114:\tlearn: 1.0104983\ttotal: 2m 47s\tremaining: 21m 31s\n",
      "115:\tlearn: 1.0057942\ttotal: 2m 49s\tremaining: 21m 30s\n",
      "116:\tlearn: 1.0036625\ttotal: 2m 50s\tremaining: 21m 28s\n",
      "117:\tlearn: 1.0014735\ttotal: 2m 52s\tremaining: 21m 27s\n",
      "118:\tlearn: 0.9997000\ttotal: 2m 53s\tremaining: 21m 25s\n",
      "119:\tlearn: 0.9966165\ttotal: 2m 55s\tremaining: 21m 23s\n",
      "120:\tlearn: 0.9922441\ttotal: 2m 56s\tremaining: 21m 22s\n",
      "121:\tlearn: 0.9884423\ttotal: 2m 57s\tremaining: 21m 20s\n",
      "122:\tlearn: 0.9849965\ttotal: 2m 59s\tremaining: 21m 19s\n",
      "123:\tlearn: 0.9819310\ttotal: 3m\tremaining: 21m 17s\n",
      "124:\tlearn: 0.9792668\ttotal: 3m 2s\tremaining: 21m 15s\n",
      "125:\tlearn: 0.9755366\ttotal: 3m 3s\tremaining: 21m 14s\n",
      "126:\tlearn: 0.9730577\ttotal: 3m 5s\tremaining: 21m 12s\n",
      "127:\tlearn: 0.9697705\ttotal: 3m 6s\tremaining: 21m 11s\n",
      "128:\tlearn: 0.9665768\ttotal: 3m 8s\tremaining: 21m 9s\n",
      "129:\tlearn: 0.9635884\ttotal: 3m 9s\tremaining: 21m 7s\n",
      "130:\tlearn: 0.9599136\ttotal: 3m 11s\tremaining: 21m 7s\n",
      "131:\tlearn: 0.9565649\ttotal: 3m 12s\tremaining: 21m 7s\n",
      "132:\tlearn: 0.9539834\ttotal: 3m 14s\tremaining: 21m 8s\n",
      "133:\tlearn: 0.9511798\ttotal: 3m 16s\tremaining: 21m 8s\n",
      "134:\tlearn: 0.9475800\ttotal: 3m 17s\tremaining: 21m 8s\n",
      "135:\tlearn: 0.9450326\ttotal: 3m 19s\tremaining: 21m 8s\n",
      "136:\tlearn: 0.9423596\ttotal: 3m 21s\tremaining: 21m 7s\n",
      "137:\tlearn: 0.9391699\ttotal: 3m 22s\tremaining: 21m 7s\n",
      "138:\tlearn: 0.9369040\ttotal: 3m 24s\tremaining: 21m 9s\n",
      "139:\tlearn: 0.9334866\ttotal: 3m 26s\tremaining: 21m 10s\n",
      "140:\tlearn: 0.9308641\ttotal: 3m 28s\tremaining: 21m 11s\n",
      "141:\tlearn: 0.9285426\ttotal: 3m 30s\tremaining: 21m 13s\n",
      "142:\tlearn: 0.9265216\ttotal: 3m 32s\tremaining: 21m 12s\n",
      "143:\tlearn: 0.9230795\ttotal: 3m 33s\tremaining: 21m 11s\n",
      "144:\tlearn: 0.9207221\ttotal: 3m 35s\tremaining: 21m 10s\n",
      "145:\tlearn: 0.9186500\ttotal: 3m 36s\tremaining: 21m 8s\n",
      "146:\tlearn: 0.9156267\ttotal: 3m 38s\tremaining: 21m 7s\n",
      "147:\tlearn: 0.9121471\ttotal: 3m 39s\tremaining: 21m 6s\n",
      "148:\tlearn: 0.9102262\ttotal: 3m 41s\tremaining: 21m 4s\n",
      "149:\tlearn: 0.9065398\ttotal: 3m 42s\tremaining: 21m 3s\n",
      "150:\tlearn: 0.9021752\ttotal: 3m 44s\tremaining: 21m 2s\n",
      "151:\tlearn: 0.8996895\ttotal: 3m 45s\tremaining: 21m\n",
      "152:\tlearn: 0.8972227\ttotal: 3m 47s\tremaining: 20m 59s\n",
      "153:\tlearn: 0.8941131\ttotal: 3m 48s\tremaining: 20m 57s\n",
      "154:\tlearn: 0.8915582\ttotal: 3m 50s\tremaining: 20m 56s\n",
      "155:\tlearn: 0.8895047\ttotal: 3m 51s\tremaining: 20m 54s\n",
      "156:\tlearn: 0.8877996\ttotal: 3m 53s\tremaining: 20m 53s\n",
      "157:\tlearn: 0.8847141\ttotal: 3m 55s\tremaining: 20m 52s\n",
      "158:\tlearn: 0.8809723\ttotal: 3m 56s\tremaining: 20m 51s\n",
      "159:\tlearn: 0.8784484\ttotal: 3m 58s\tremaining: 20m 50s\n",
      "160:\tlearn: 0.8759621\ttotal: 3m 59s\tremaining: 20m 49s\n",
      "161:\tlearn: 0.8731533\ttotal: 4m 1s\tremaining: 20m 47s\n",
      "162:\tlearn: 0.8713771\ttotal: 4m 2s\tremaining: 20m 46s\n",
      "163:\tlearn: 0.8693915\ttotal: 4m 4s\tremaining: 20m 44s\n",
      "164:\tlearn: 0.8666960\ttotal: 4m 5s\tremaining: 20m 42s\n",
      "165:\tlearn: 0.8645500\ttotal: 4m 6s\tremaining: 20m 40s\n",
      "166:\tlearn: 0.8620950\ttotal: 4m 8s\tremaining: 20m 38s\n",
      "167:\tlearn: 0.8594329\ttotal: 4m 9s\tremaining: 20m 37s\n",
      "168:\tlearn: 0.8575437\ttotal: 4m 11s\tremaining: 20m 35s\n",
      "169:\tlearn: 0.8550676\ttotal: 4m 12s\tremaining: 20m 33s\n",
      "170:\tlearn: 0.8523986\ttotal: 4m 14s\tremaining: 20m 31s\n",
      "171:\tlearn: 0.8508451\ttotal: 4m 15s\tremaining: 20m 30s\n",
      "172:\tlearn: 0.8486988\ttotal: 4m 16s\tremaining: 20m 28s\n",
      "173:\tlearn: 0.8464053\ttotal: 4m 18s\tremaining: 20m 26s\n",
      "174:\tlearn: 0.8435252\ttotal: 4m 19s\tremaining: 20m 24s\n",
      "175:\tlearn: 0.8401337\ttotal: 4m 21s\tremaining: 20m 22s\n",
      "176:\tlearn: 0.8386519\ttotal: 4m 22s\tremaining: 20m 21s\n",
      "177:\tlearn: 0.8372710\ttotal: 4m 24s\tremaining: 20m 19s\n",
      "178:\tlearn: 0.8351073\ttotal: 4m 25s\tremaining: 20m 17s\n",
      "179:\tlearn: 0.8319755\ttotal: 4m 26s\tremaining: 20m 15s\n",
      "180:\tlearn: 0.8303743\ttotal: 4m 28s\tremaining: 20m 14s\n",
      "181:\tlearn: 0.8284647\ttotal: 4m 29s\tremaining: 20m 12s\n",
      "182:\tlearn: 0.8267548\ttotal: 4m 31s\tremaining: 20m 11s\n",
      "183:\tlearn: 0.8239347\ttotal: 4m 32s\tremaining: 20m 9s\n",
      "184:\tlearn: 0.8213603\ttotal: 4m 34s\tremaining: 20m 9s\n",
      "185:\tlearn: 0.8193017\ttotal: 4m 36s\tremaining: 20m 11s\n",
      "186:\tlearn: 0.8167734\ttotal: 4m 38s\tremaining: 20m 10s\n",
      "187:\tlearn: 0.8137312\ttotal: 4m 40s\tremaining: 20m 12s\n",
      "188:\tlearn: 0.8104851\ttotal: 4m 43s\tremaining: 20m 16s\n",
      "189:\tlearn: 0.8081808\ttotal: 4m 45s\tremaining: 20m 19s\n",
      "190:\tlearn: 0.8065838\ttotal: 4m 48s\tremaining: 20m 20s\n",
      "191:\tlearn: 0.8030896\ttotal: 4m 50s\tremaining: 20m 23s\n",
      "192:\tlearn: 0.8012362\ttotal: 4m 52s\tremaining: 20m 22s\n",
      "193:\tlearn: 0.7989381\ttotal: 4m 54s\tremaining: 20m 22s\n",
      "194:\tlearn: 0.7971885\ttotal: 4m 55s\tremaining: 20m 21s\n",
      "195:\tlearn: 0.7957358\ttotal: 4m 57s\tremaining: 20m 20s\n",
      "196:\tlearn: 0.7939281\ttotal: 4m 59s\tremaining: 20m 18s\n",
      "197:\tlearn: 0.7918361\ttotal: 5m\tremaining: 20m 17s\n",
      "198:\tlearn: 0.7894297\ttotal: 5m 2s\tremaining: 20m 16s\n",
      "199:\tlearn: 0.7868572\ttotal: 5m 3s\tremaining: 20m 14s\n",
      "200:\tlearn: 0.7855738\ttotal: 5m 5s\tremaining: 20m 13s\n",
      "201:\tlearn: 0.7822289\ttotal: 5m 6s\tremaining: 20m 12s\n",
      "202:\tlearn: 0.7795227\ttotal: 5m 8s\tremaining: 20m 11s\n",
      "203:\tlearn: 0.7775269\ttotal: 5m 10s\tremaining: 20m 9s\n",
      "204:\tlearn: 0.7748157\ttotal: 5m 11s\tremaining: 20m 8s\n",
      "205:\tlearn: 0.7726220\ttotal: 5m 13s\tremaining: 20m 9s\n",
      "206:\tlearn: 0.7710852\ttotal: 5m 15s\tremaining: 20m 8s\n",
      "207:\tlearn: 0.7696207\ttotal: 5m 17s\tremaining: 20m 7s\n",
      "208:\tlearn: 0.7669662\ttotal: 5m 18s\tremaining: 20m 6s\n",
      "209:\tlearn: 0.7649106\ttotal: 5m 20s\tremaining: 20m 6s\n",
      "210:\tlearn: 0.7639536\ttotal: 5m 22s\tremaining: 20m 5s\n",
      "211:\tlearn: 0.7621873\ttotal: 5m 24s\tremaining: 20m 4s\n",
      "212:\tlearn: 0.7594112\ttotal: 5m 26s\tremaining: 20m 6s\n",
      "213:\tlearn: 0.7575203\ttotal: 5m 28s\tremaining: 20m 7s\n",
      "214:\tlearn: 0.7546851\ttotal: 5m 30s\tremaining: 20m 8s\n",
      "215:\tlearn: 0.7523926\ttotal: 5m 32s\tremaining: 20m 7s\n",
      "216:\tlearn: 0.7506722\ttotal: 5m 34s\tremaining: 20m 6s\n",
      "217:\tlearn: 0.7488757\ttotal: 5m 35s\tremaining: 20m 4s\n",
      "218:\tlearn: 0.7467850\ttotal: 5m 37s\tremaining: 20m 3s\n",
      "219:\tlearn: 0.7444717\ttotal: 5m 39s\tremaining: 20m 3s\n",
      "220:\tlearn: 0.7432230\ttotal: 5m 41s\tremaining: 20m 2s\n",
      "221:\tlearn: 0.7408613\ttotal: 5m 42s\tremaining: 20m 1s\n",
      "222:\tlearn: 0.7370566\ttotal: 5m 44s\tremaining: 19m 59s\n",
      "223:\tlearn: 0.7346261\ttotal: 5m 45s\tremaining: 19m 58s\n",
      "224:\tlearn: 0.7320883\ttotal: 5m 47s\tremaining: 19m 56s\n",
      "225:\tlearn: 0.7292628\ttotal: 5m 49s\tremaining: 19m 55s\n",
      "226:\tlearn: 0.7264411\ttotal: 5m 50s\tremaining: 19m 54s\n",
      "227:\tlearn: 0.7245021\ttotal: 5m 52s\tremaining: 19m 52s\n",
      "228:\tlearn: 0.7225337\ttotal: 5m 53s\tremaining: 19m 51s\n",
      "229:\tlearn: 0.7213748\ttotal: 5m 55s\tremaining: 19m 49s\n",
      "230:\tlearn: 0.7194630\ttotal: 5m 56s\tremaining: 19m 47s\n",
      "231:\tlearn: 0.7180295\ttotal: 5m 58s\tremaining: 19m 46s\n",
      "232:\tlearn: 0.7162535\ttotal: 5m 59s\tremaining: 19m 44s\n",
      "233:\tlearn: 0.7142847\ttotal: 6m 1s\tremaining: 19m 43s\n",
      "234:\tlearn: 0.7123924\ttotal: 6m 2s\tremaining: 19m 41s\n",
      "235:\tlearn: 0.7107325\ttotal: 6m 4s\tremaining: 19m 40s\n",
      "236:\tlearn: 0.7092422\ttotal: 6m 6s\tremaining: 19m 38s\n",
      "237:\tlearn: 0.7070965\ttotal: 6m 7s\tremaining: 19m 36s\n",
      "238:\tlearn: 0.7051996\ttotal: 6m 9s\tremaining: 19m 35s\n",
      "239:\tlearn: 0.7034442\ttotal: 6m 10s\tremaining: 19m 34s\n",
      "240:\tlearn: 0.7014821\ttotal: 6m 12s\tremaining: 19m 32s\n",
      "241:\tlearn: 0.6990779\ttotal: 6m 13s\tremaining: 19m 31s\n",
      "242:\tlearn: 0.6974992\ttotal: 6m 15s\tremaining: 19m 29s\n",
      "243:\tlearn: 0.6949490\ttotal: 6m 17s\tremaining: 19m 28s\n",
      "244:\tlearn: 0.6933352\ttotal: 6m 18s\tremaining: 19m 26s\n",
      "245:\tlearn: 0.6904961\ttotal: 6m 20s\tremaining: 19m 25s\n",
      "246:\tlearn: 0.6880005\ttotal: 6m 21s\tremaining: 19m 24s\n",
      "247:\tlearn: 0.6856043\ttotal: 6m 23s\tremaining: 19m 22s\n",
      "248:\tlearn: 0.6839419\ttotal: 6m 24s\tremaining: 19m 21s\n",
      "249:\tlearn: 0.6821838\ttotal: 6m 26s\tremaining: 19m 19s\n",
      "250:\tlearn: 0.6802421\ttotal: 6m 27s\tremaining: 19m 17s\n",
      "251:\tlearn: 0.6783303\ttotal: 6m 29s\tremaining: 19m 16s\n",
      "252:\tlearn: 0.6762845\ttotal: 6m 31s\tremaining: 19m 15s\n",
      "253:\tlearn: 0.6731799\ttotal: 6m 32s\tremaining: 19m 13s\n",
      "254:\tlearn: 0.6716536\ttotal: 6m 34s\tremaining: 19m 12s\n",
      "255:\tlearn: 0.6701716\ttotal: 6m 36s\tremaining: 19m 10s\n",
      "256:\tlearn: 0.6674729\ttotal: 6m 37s\tremaining: 19m 9s\n",
      "257:\tlearn: 0.6653015\ttotal: 6m 39s\tremaining: 19m 8s\n",
      "258:\tlearn: 0.6637797\ttotal: 6m 41s\tremaining: 19m 7s\n",
      "259:\tlearn: 0.6625095\ttotal: 6m 42s\tremaining: 19m 6s\n",
      "260:\tlearn: 0.6605755\ttotal: 6m 44s\tremaining: 19m 5s\n",
      "261:\tlearn: 0.6591906\ttotal: 6m 46s\tremaining: 19m 3s\n",
      "262:\tlearn: 0.6570028\ttotal: 6m 47s\tremaining: 19m 2s\n",
      "263:\tlearn: 0.6553870\ttotal: 6m 49s\tremaining: 19m\n",
      "264:\tlearn: 0.6538479\ttotal: 6m 50s\tremaining: 18m 59s\n",
      "265:\tlearn: 0.6520427\ttotal: 6m 52s\tremaining: 18m 57s\n",
      "266:\tlearn: 0.6508752\ttotal: 6m 53s\tremaining: 18m 55s\n",
      "267:\tlearn: 0.6491936\ttotal: 6m 55s\tremaining: 18m 54s\n",
      "268:\tlearn: 0.6477129\ttotal: 6m 57s\tremaining: 18m 54s\n",
      "269:\tlearn: 0.6463738\ttotal: 6m 59s\tremaining: 18m 53s\n",
      "270:\tlearn: 0.6454650\ttotal: 7m 1s\tremaining: 18m 53s\n",
      "271:\tlearn: 0.6441375\ttotal: 7m 3s\tremaining: 18m 54s\n",
      "272:\tlearn: 0.6423087\ttotal: 7m 5s\tremaining: 18m 54s\n",
      "273:\tlearn: 0.6414596\ttotal: 7m 7s\tremaining: 18m 53s\n",
      "274:\tlearn: 0.6402105\ttotal: 7m 9s\tremaining: 18m 53s\n",
      "275:\tlearn: 0.6382005\ttotal: 7m 11s\tremaining: 18m 52s\n",
      "276:\tlearn: 0.6370418\ttotal: 7m 13s\tremaining: 18m 51s\n",
      "277:\tlearn: 0.6356946\ttotal: 7m 14s\tremaining: 18m 49s\n",
      "278:\tlearn: 0.6345622\ttotal: 7m 16s\tremaining: 18m 47s\n",
      "279:\tlearn: 0.6325009\ttotal: 7m 17s\tremaining: 18m 46s\n",
      "280:\tlearn: 0.6304437\ttotal: 7m 19s\tremaining: 18m 44s\n",
      "281:\tlearn: 0.6293019\ttotal: 7m 20s\tremaining: 18m 42s\n",
      "282:\tlearn: 0.6279817\ttotal: 7m 22s\tremaining: 18m 40s\n",
      "283:\tlearn: 0.6273240\ttotal: 7m 23s\tremaining: 18m 38s\n",
      "284:\tlearn: 0.6249819\ttotal: 7m 25s\tremaining: 18m 36s\n",
      "285:\tlearn: 0.6232622\ttotal: 7m 26s\tremaining: 18m 34s\n",
      "286:\tlearn: 0.6212478\ttotal: 7m 28s\tremaining: 18m 33s\n",
      "287:\tlearn: 0.6188311\ttotal: 7m 29s\tremaining: 18m 31s\n",
      "288:\tlearn: 0.6165179\ttotal: 7m 31s\tremaining: 18m 29s\n",
      "289:\tlearn: 0.6152905\ttotal: 7m 32s\tremaining: 18m 27s\n",
      "290:\tlearn: 0.6134473\ttotal: 7m 33s\tremaining: 18m 26s\n",
      "291:\tlearn: 0.6117406\ttotal: 7m 35s\tremaining: 18m 24s\n",
      "292:\tlearn: 0.6103652\ttotal: 7m 36s\tremaining: 18m 22s\n",
      "293:\tlearn: 0.6091809\ttotal: 7m 38s\tremaining: 18m 20s\n",
      "294:\tlearn: 0.6068398\ttotal: 7m 39s\tremaining: 18m 18s\n",
      "295:\tlearn: 0.6048636\ttotal: 7m 41s\tremaining: 18m 16s\n",
      "296:\tlearn: 0.6036147\ttotal: 7m 42s\tremaining: 18m 15s\n",
      "297:\tlearn: 0.6017457\ttotal: 7m 44s\tremaining: 18m 13s\n",
      "298:\tlearn: 0.6005511\ttotal: 7m 45s\tremaining: 18m 11s\n",
      "299:\tlearn: 0.5988565\ttotal: 7m 47s\tremaining: 18m 9s\n",
      "300:\tlearn: 0.5975660\ttotal: 7m 48s\tremaining: 18m 7s\n",
      "301:\tlearn: 0.5957104\ttotal: 7m 49s\tremaining: 18m 6s\n",
      "302:\tlearn: 0.5943822\ttotal: 7m 51s\tremaining: 18m 4s\n",
      "303:\tlearn: 0.5929048\ttotal: 7m 52s\tremaining: 18m 2s\n",
      "304:\tlearn: 0.5920461\ttotal: 7m 54s\tremaining: 18m\n",
      "305:\tlearn: 0.5906155\ttotal: 7m 55s\tremaining: 17m 58s\n",
      "306:\tlearn: 0.5890453\ttotal: 7m 57s\tremaining: 17m 56s\n",
      "307:\tlearn: 0.5870574\ttotal: 7m 58s\tremaining: 17m 55s\n",
      "308:\tlearn: 0.5860957\ttotal: 8m\tremaining: 17m 53s\n",
      "309:\tlearn: 0.5846894\ttotal: 8m 1s\tremaining: 17m 51s\n",
      "310:\tlearn: 0.5831632\ttotal: 8m 3s\tremaining: 17m 50s\n",
      "311:\tlearn: 0.5818237\ttotal: 8m 4s\tremaining: 17m 48s\n",
      "312:\tlearn: 0.5808040\ttotal: 8m 5s\tremaining: 17m 46s\n",
      "313:\tlearn: 0.5791395\ttotal: 8m 7s\tremaining: 17m 44s\n",
      "314:\tlearn: 0.5777578\ttotal: 8m 8s\tremaining: 17m 43s\n",
      "315:\tlearn: 0.5764266\ttotal: 8m 10s\tremaining: 17m 41s\n",
      "316:\tlearn: 0.5750796\ttotal: 8m 11s\tremaining: 17m 39s\n",
      "317:\tlearn: 0.5737285\ttotal: 8m 13s\tremaining: 17m 37s\n",
      "318:\tlearn: 0.5716686\ttotal: 8m 14s\tremaining: 17m 36s\n",
      "319:\tlearn: 0.5698614\ttotal: 8m 16s\tremaining: 17m 34s\n",
      "320:\tlearn: 0.5677359\ttotal: 8m 17s\tremaining: 17m 32s\n",
      "321:\tlearn: 0.5665823\ttotal: 8m 19s\tremaining: 17m 30s\n",
      "322:\tlearn: 0.5657406\ttotal: 8m 20s\tremaining: 17m 28s\n",
      "323:\tlearn: 0.5644556\ttotal: 8m 21s\tremaining: 17m 27s\n",
      "324:\tlearn: 0.5623732\ttotal: 8m 23s\tremaining: 17m 25s\n",
      "325:\tlearn: 0.5603416\ttotal: 8m 24s\tremaining: 17m 23s\n",
      "326:\tlearn: 0.5594211\ttotal: 8m 26s\tremaining: 17m 21s\n",
      "327:\tlearn: 0.5587220\ttotal: 8m 27s\tremaining: 17m 20s\n",
      "328:\tlearn: 0.5571982\ttotal: 8m 29s\tremaining: 17m 18s\n",
      "329:\tlearn: 0.5551797\ttotal: 8m 30s\tremaining: 17m 16s\n",
      "330:\tlearn: 0.5542460\ttotal: 8m 32s\tremaining: 17m 14s\n",
      "331:\tlearn: 0.5524841\ttotal: 8m 33s\tremaining: 17m 13s\n",
      "332:\tlearn: 0.5507272\ttotal: 8m 34s\tremaining: 17m 11s\n",
      "333:\tlearn: 0.5495571\ttotal: 8m 36s\tremaining: 17m 9s\n",
      "334:\tlearn: 0.5479596\ttotal: 8m 37s\tremaining: 17m 8s\n",
      "335:\tlearn: 0.5470346\ttotal: 8m 39s\tremaining: 17m 6s\n",
      "336:\tlearn: 0.5461386\ttotal: 8m 40s\tremaining: 17m 4s\n",
      "337:\tlearn: 0.5450616\ttotal: 8m 42s\tremaining: 17m 2s\n",
      "338:\tlearn: 0.5440576\ttotal: 8m 43s\tremaining: 17m 1s\n",
      "339:\tlearn: 0.5430989\ttotal: 8m 45s\tremaining: 16m 59s\n",
      "340:\tlearn: 0.5412564\ttotal: 8m 46s\tremaining: 16m 58s\n",
      "341:\tlearn: 0.5400795\ttotal: 8m 48s\tremaining: 16m 56s\n",
      "342:\tlearn: 0.5389334\ttotal: 8m 49s\tremaining: 16m 54s\n",
      "343:\tlearn: 0.5375512\ttotal: 8m 51s\tremaining: 16m 52s\n",
      "344:\tlearn: 0.5361093\ttotal: 8m 52s\tremaining: 16m 51s\n",
      "345:\tlearn: 0.5349780\ttotal: 8m 54s\tremaining: 16m 49s\n",
      "346:\tlearn: 0.5336899\ttotal: 8m 55s\tremaining: 16m 48s\n",
      "347:\tlearn: 0.5329512\ttotal: 8m 57s\tremaining: 16m 46s\n",
      "348:\tlearn: 0.5321450\ttotal: 8m 58s\tremaining: 16m 44s\n",
      "349:\tlearn: 0.5310000\ttotal: 9m\tremaining: 16m 42s\n",
      "350:\tlearn: 0.5295295\ttotal: 9m 1s\tremaining: 16m 41s\n",
      "351:\tlearn: 0.5286851\ttotal: 9m 2s\tremaining: 16m 39s\n",
      "352:\tlearn: 0.5277544\ttotal: 9m 4s\tremaining: 16m 37s\n",
      "353:\tlearn: 0.5267176\ttotal: 9m 5s\tremaining: 16m 36s\n",
      "354:\tlearn: 0.5253602\ttotal: 9m 7s\tremaining: 16m 34s\n",
      "355:\tlearn: 0.5239301\ttotal: 9m 8s\tremaining: 16m 32s\n",
      "356:\tlearn: 0.5227844\ttotal: 9m 10s\tremaining: 16m 30s\n",
      "357:\tlearn: 0.5220493\ttotal: 9m 11s\tremaining: 16m 29s\n",
      "358:\tlearn: 0.5210310\ttotal: 9m 13s\tremaining: 16m 27s\n",
      "359:\tlearn: 0.5199124\ttotal: 9m 14s\tremaining: 16m 25s\n",
      "360:\tlearn: 0.5186074\ttotal: 9m 15s\tremaining: 16m 24s\n",
      "361:\tlearn: 0.5178051\ttotal: 9m 17s\tremaining: 16m 22s\n",
      "362:\tlearn: 0.5165443\ttotal: 9m 18s\tremaining: 16m 20s\n",
      "363:\tlearn: 0.5158832\ttotal: 9m 20s\tremaining: 16m 18s\n",
      "364:\tlearn: 0.5148611\ttotal: 9m 21s\tremaining: 16m 17s\n",
      "365:\tlearn: 0.5142490\ttotal: 9m 23s\tremaining: 16m 15s\n",
      "366:\tlearn: 0.5127390\ttotal: 9m 24s\tremaining: 16m 13s\n",
      "367:\tlearn: 0.5119417\ttotal: 9m 26s\tremaining: 16m 12s\n",
      "368:\tlearn: 0.5105245\ttotal: 9m 27s\tremaining: 16m 10s\n",
      "369:\tlearn: 0.5095728\ttotal: 9m 29s\tremaining: 16m 8s\n",
      "370:\tlearn: 0.5082066\ttotal: 9m 30s\tremaining: 16m 7s\n",
      "371:\tlearn: 0.5072082\ttotal: 9m 31s\tremaining: 16m 5s\n",
      "372:\tlearn: 0.5063503\ttotal: 9m 33s\tremaining: 16m 3s\n",
      "373:\tlearn: 0.5054953\ttotal: 9m 35s\tremaining: 16m 2s\n",
      "374:\tlearn: 0.5041061\ttotal: 9m 36s\tremaining: 16m\n",
      "375:\tlearn: 0.5029177\ttotal: 9m 37s\tremaining: 15m 59s\n",
      "376:\tlearn: 0.5020103\ttotal: 9m 39s\tremaining: 15m 57s\n",
      "377:\tlearn: 0.5010189\ttotal: 9m 40s\tremaining: 15m 55s\n",
      "378:\tlearn: 0.5002466\ttotal: 9m 42s\tremaining: 15m 53s\n",
      "379:\tlearn: 0.4989081\ttotal: 9m 43s\tremaining: 15m 52s\n",
      "380:\tlearn: 0.4981988\ttotal: 9m 45s\tremaining: 15m 50s\n",
      "381:\tlearn: 0.4973163\ttotal: 9m 46s\tremaining: 15m 48s\n",
      "382:\tlearn: 0.4961583\ttotal: 9m 47s\tremaining: 15m 47s\n",
      "383:\tlearn: 0.4949848\ttotal: 9m 49s\tremaining: 15m 45s\n",
      "384:\tlearn: 0.4939983\ttotal: 9m 50s\tremaining: 15m 43s\n",
      "385:\tlearn: 0.4931846\ttotal: 9m 52s\tremaining: 15m 42s\n",
      "386:\tlearn: 0.4921780\ttotal: 9m 53s\tremaining: 15m 40s\n",
      "387:\tlearn: 0.4911141\ttotal: 9m 55s\tremaining: 15m 38s\n",
      "388:\tlearn: 0.4902317\ttotal: 9m 56s\tremaining: 15m 37s\n",
      "389:\tlearn: 0.4887372\ttotal: 9m 58s\tremaining: 15m 35s\n",
      "390:\tlearn: 0.4880367\ttotal: 9m 59s\tremaining: 15m 33s\n",
      "391:\tlearn: 0.4872794\ttotal: 10m\tremaining: 15m 32s\n",
      "392:\tlearn: 0.4863095\ttotal: 10m 2s\tremaining: 15m 30s\n",
      "393:\tlearn: 0.4847742\ttotal: 10m 3s\tremaining: 15m 28s\n",
      "394:\tlearn: 0.4840638\ttotal: 10m 5s\tremaining: 15m 27s\n",
      "395:\tlearn: 0.4835959\ttotal: 10m 6s\tremaining: 15m 25s\n",
      "396:\tlearn: 0.4825377\ttotal: 10m 8s\tremaining: 15m 23s\n",
      "397:\tlearn: 0.4818335\ttotal: 10m 9s\tremaining: 15m 22s\n",
      "398:\tlearn: 0.4804061\ttotal: 10m 11s\tremaining: 15m 20s\n",
      "399:\tlearn: 0.4792534\ttotal: 10m 12s\tremaining: 15m 18s\n",
      "400:\tlearn: 0.4778275\ttotal: 10m 13s\tremaining: 15m 17s\n",
      "401:\tlearn: 0.4768683\ttotal: 10m 15s\tremaining: 15m 15s\n",
      "402:\tlearn: 0.4750810\ttotal: 10m 16s\tremaining: 15m 13s\n",
      "403:\tlearn: 0.4735887\ttotal: 10m 18s\tremaining: 15m 12s\n",
      "404:\tlearn: 0.4722797\ttotal: 10m 19s\tremaining: 15m 10s\n",
      "405:\tlearn: 0.4712260\ttotal: 10m 21s\tremaining: 15m 8s\n",
      "406:\tlearn: 0.4696270\ttotal: 10m 22s\tremaining: 15m 7s\n",
      "407:\tlearn: 0.4689119\ttotal: 10m 24s\tremaining: 15m 5s\n",
      "408:\tlearn: 0.4682026\ttotal: 10m 25s\tremaining: 15m 3s\n",
      "409:\tlearn: 0.4676523\ttotal: 10m 27s\tremaining: 15m 2s\n",
      "410:\tlearn: 0.4661456\ttotal: 10m 28s\tremaining: 15m\n",
      "411:\tlearn: 0.4652973\ttotal: 10m 29s\tremaining: 14m 59s\n",
      "412:\tlearn: 0.4639724\ttotal: 10m 31s\tremaining: 14m 57s\n",
      "413:\tlearn: 0.4627623\ttotal: 10m 32s\tremaining: 14m 55s\n",
      "414:\tlearn: 0.4610792\ttotal: 10m 34s\tremaining: 14m 54s\n",
      "415:\tlearn: 0.4602554\ttotal: 10m 35s\tremaining: 14m 52s\n",
      "416:\tlearn: 0.4592665\ttotal: 10m 37s\tremaining: 14m 50s\n",
      "417:\tlearn: 0.4583492\ttotal: 10m 38s\tremaining: 14m 49s\n",
      "418:\tlearn: 0.4572355\ttotal: 10m 40s\tremaining: 14m 47s\n",
      "419:\tlearn: 0.4558505\ttotal: 10m 41s\tremaining: 14m 46s\n",
      "420:\tlearn: 0.4542963\ttotal: 10m 43s\tremaining: 14m 44s\n",
      "421:\tlearn: 0.4529355\ttotal: 10m 44s\tremaining: 14m 42s\n",
      "422:\tlearn: 0.4520796\ttotal: 10m 46s\tremaining: 14m 41s\n",
      "423:\tlearn: 0.4511019\ttotal: 10m 47s\tremaining: 14m 39s\n",
      "424:\tlearn: 0.4498815\ttotal: 10m 48s\tremaining: 14m 38s\n",
      "425:\tlearn: 0.4485408\ttotal: 10m 50s\tremaining: 14m 36s\n",
      "426:\tlearn: 0.4477681\ttotal: 10m 51s\tremaining: 14m 34s\n",
      "427:\tlearn: 0.4467601\ttotal: 10m 53s\tremaining: 14m 33s\n",
      "428:\tlearn: 0.4461045\ttotal: 10m 54s\tremaining: 14m 31s\n",
      "429:\tlearn: 0.4454053\ttotal: 10m 56s\tremaining: 14m 29s\n",
      "430:\tlearn: 0.4446420\ttotal: 10m 57s\tremaining: 14m 28s\n",
      "431:\tlearn: 0.4432490\ttotal: 10m 59s\tremaining: 14m 26s\n",
      "432:\tlearn: 0.4423617\ttotal: 11m\tremaining: 14m 24s\n",
      "433:\tlearn: 0.4415886\ttotal: 11m 1s\tremaining: 14m 23s\n",
      "434:\tlearn: 0.4404245\ttotal: 11m 3s\tremaining: 14m 21s\n",
      "435:\tlearn: 0.4396304\ttotal: 11m 4s\tremaining: 14m 20s\n",
      "436:\tlearn: 0.4387385\ttotal: 11m 6s\tremaining: 14m 18s\n",
      "437:\tlearn: 0.4373847\ttotal: 11m 7s\tremaining: 14m 16s\n",
      "438:\tlearn: 0.4369973\ttotal: 11m 9s\tremaining: 14m 15s\n",
      "439:\tlearn: 0.4360094\ttotal: 11m 10s\tremaining: 14m 13s\n",
      "440:\tlearn: 0.4352023\ttotal: 11m 12s\tremaining: 14m 11s\n",
      "441:\tlearn: 0.4341701\ttotal: 11m 13s\tremaining: 14m 10s\n",
      "442:\tlearn: 0.4333739\ttotal: 11m 14s\tremaining: 14m 8s\n",
      "443:\tlearn: 0.4324426\ttotal: 11m 16s\tremaining: 14m 7s\n",
      "444:\tlearn: 0.4317605\ttotal: 11m 18s\tremaining: 14m 5s\n",
      "445:\tlearn: 0.4314238\ttotal: 11m 19s\tremaining: 14m 4s\n",
      "446:\tlearn: 0.4299375\ttotal: 11m 21s\tremaining: 14m 2s\n",
      "447:\tlearn: 0.4285646\ttotal: 11m 22s\tremaining: 14m 1s\n",
      "448:\tlearn: 0.4278700\ttotal: 11m 24s\tremaining: 13m 59s\n",
      "449:\tlearn: 0.4264492\ttotal: 11m 25s\tremaining: 13m 57s\n",
      "450:\tlearn: 0.4252721\ttotal: 11m 26s\tremaining: 13m 56s\n",
      "451:\tlearn: 0.4243252\ttotal: 11m 28s\tremaining: 13m 54s\n",
      "452:\tlearn: 0.4236417\ttotal: 11m 29s\tremaining: 13m 52s\n",
      "453:\tlearn: 0.4231558\ttotal: 11m 31s\tremaining: 13m 51s\n",
      "454:\tlearn: 0.4219589\ttotal: 11m 32s\tremaining: 13m 49s\n",
      "455:\tlearn: 0.4213867\ttotal: 11m 34s\tremaining: 13m 48s\n",
      "456:\tlearn: 0.4202148\ttotal: 11m 35s\tremaining: 13m 46s\n",
      "457:\tlearn: 0.4196772\ttotal: 11m 36s\tremaining: 13m 44s\n",
      "458:\tlearn: 0.4188043\ttotal: 11m 38s\tremaining: 13m 43s\n",
      "459:\tlearn: 0.4179203\ttotal: 11m 39s\tremaining: 13m 41s\n",
      "460:\tlearn: 0.4171004\ttotal: 11m 41s\tremaining: 13m 39s\n",
      "461:\tlearn: 0.4161044\ttotal: 11m 42s\tremaining: 13m 38s\n",
      "462:\tlearn: 0.4154764\ttotal: 11m 44s\tremaining: 13m 36s\n",
      "463:\tlearn: 0.4144338\ttotal: 11m 45s\tremaining: 13m 35s\n",
      "464:\tlearn: 0.4133762\ttotal: 11m 47s\tremaining: 13m 33s\n",
      "465:\tlearn: 0.4125312\ttotal: 11m 48s\tremaining: 13m 32s\n",
      "466:\tlearn: 0.4118000\ttotal: 11m 50s\tremaining: 13m 30s\n",
      "467:\tlearn: 0.4112369\ttotal: 11m 51s\tremaining: 13m 29s\n",
      "468:\tlearn: 0.4100291\ttotal: 11m 53s\tremaining: 13m 27s\n",
      "469:\tlearn: 0.4088560\ttotal: 11m 54s\tremaining: 13m 25s\n",
      "470:\tlearn: 0.4079741\ttotal: 11m 56s\tremaining: 13m 24s\n",
      "471:\tlearn: 0.4069595\ttotal: 11m 57s\tremaining: 13m 22s\n",
      "472:\tlearn: 0.4060523\ttotal: 11m 58s\tremaining: 13m 21s\n",
      "473:\tlearn: 0.4052597\ttotal: 12m\tremaining: 13m 19s\n",
      "474:\tlearn: 0.4041933\ttotal: 12m 1s\tremaining: 13m 17s\n",
      "475:\tlearn: 0.4032500\ttotal: 12m 3s\tremaining: 13m 16s\n",
      "476:\tlearn: 0.4024918\ttotal: 12m 4s\tremaining: 13m 14s\n",
      "477:\tlearn: 0.4016018\ttotal: 12m 6s\tremaining: 13m 13s\n",
      "478:\tlearn: 0.4007124\ttotal: 12m 7s\tremaining: 13m 11s\n",
      "479:\tlearn: 0.3994956\ttotal: 12m 9s\tremaining: 13m 9s\n",
      "480:\tlearn: 0.3984105\ttotal: 12m 10s\tremaining: 13m 8s\n",
      "481:\tlearn: 0.3975417\ttotal: 12m 12s\tremaining: 13m 6s\n",
      "482:\tlearn: 0.3968526\ttotal: 12m 13s\tremaining: 13m 5s\n",
      "483:\tlearn: 0.3961270\ttotal: 12m 14s\tremaining: 13m 3s\n",
      "484:\tlearn: 0.3950001\ttotal: 12m 16s\tremaining: 13m 2s\n",
      "485:\tlearn: 0.3946694\ttotal: 12m 17s\tremaining: 13m\n",
      "486:\tlearn: 0.3937140\ttotal: 12m 19s\tremaining: 12m 58s\n",
      "487:\tlearn: 0.3924645\ttotal: 12m 20s\tremaining: 12m 57s\n",
      "488:\tlearn: 0.3918859\ttotal: 12m 22s\tremaining: 12m 55s\n",
      "489:\tlearn: 0.3905206\ttotal: 12m 23s\tremaining: 12m 54s\n",
      "490:\tlearn: 0.3895109\ttotal: 12m 25s\tremaining: 12m 52s\n",
      "491:\tlearn: 0.3891387\ttotal: 12m 26s\tremaining: 12m 50s\n",
      "492:\tlearn: 0.3880828\ttotal: 12m 28s\tremaining: 12m 49s\n",
      "493:\tlearn: 0.3873423\ttotal: 12m 29s\tremaining: 12m 47s\n",
      "494:\tlearn: 0.3867522\ttotal: 12m 31s\tremaining: 12m 46s\n",
      "495:\tlearn: 0.3861889\ttotal: 12m 32s\tremaining: 12m 44s\n",
      "496:\tlearn: 0.3853509\ttotal: 12m 33s\tremaining: 12m 43s\n",
      "497:\tlearn: 0.3848869\ttotal: 12m 35s\tremaining: 12m 41s\n",
      "498:\tlearn: 0.3842435\ttotal: 12m 36s\tremaining: 12m 39s\n",
      "499:\tlearn: 0.3838872\ttotal: 12m 38s\tremaining: 12m 38s\n",
      "500:\tlearn: 0.3825700\ttotal: 12m 39s\tremaining: 12m 36s\n",
      "501:\tlearn: 0.3815604\ttotal: 12m 41s\tremaining: 12m 35s\n",
      "502:\tlearn: 0.3809215\ttotal: 12m 42s\tremaining: 12m 33s\n",
      "503:\tlearn: 0.3804856\ttotal: 12m 43s\tremaining: 12m 31s\n",
      "504:\tlearn: 0.3800008\ttotal: 12m 45s\tremaining: 12m 30s\n",
      "505:\tlearn: 0.3789062\ttotal: 12m 46s\tremaining: 12m 28s\n",
      "506:\tlearn: 0.3781222\ttotal: 12m 48s\tremaining: 12m 27s\n",
      "507:\tlearn: 0.3772810\ttotal: 12m 49s\tremaining: 12m 25s\n",
      "508:\tlearn: 0.3764038\ttotal: 12m 51s\tremaining: 12m 23s\n",
      "509:\tlearn: 0.3754166\ttotal: 12m 52s\tremaining: 12m 22s\n",
      "510:\tlearn: 0.3744098\ttotal: 12m 54s\tremaining: 12m 20s\n",
      "511:\tlearn: 0.3737208\ttotal: 12m 55s\tremaining: 12m 19s\n",
      "512:\tlearn: 0.3734551\ttotal: 12m 56s\tremaining: 12m 17s\n",
      "513:\tlearn: 0.3725646\ttotal: 12m 58s\tremaining: 12m 15s\n",
      "514:\tlearn: 0.3719930\ttotal: 12m 59s\tremaining: 12m 14s\n",
      "515:\tlearn: 0.3712842\ttotal: 13m 1s\tremaining: 12m 12s\n",
      "516:\tlearn: 0.3702965\ttotal: 13m 2s\tremaining: 12m 11s\n",
      "517:\tlearn: 0.3694974\ttotal: 13m 4s\tremaining: 12m 9s\n",
      "518:\tlearn: 0.3687736\ttotal: 13m 5s\tremaining: 12m 8s\n",
      "519:\tlearn: 0.3678673\ttotal: 13m 7s\tremaining: 12m 6s\n",
      "520:\tlearn: 0.3670745\ttotal: 13m 8s\tremaining: 12m 5s\n",
      "521:\tlearn: 0.3662031\ttotal: 13m 10s\tremaining: 12m 3s\n",
      "522:\tlearn: 0.3651739\ttotal: 13m 11s\tremaining: 12m 1s\n",
      "523:\tlearn: 0.3643181\ttotal: 13m 12s\tremaining: 12m\n",
      "524:\tlearn: 0.3635274\ttotal: 13m 14s\tremaining: 11m 58s\n",
      "525:\tlearn: 0.3627181\ttotal: 13m 15s\tremaining: 11m 57s\n",
      "526:\tlearn: 0.3621556\ttotal: 13m 17s\tremaining: 11m 55s\n",
      "527:\tlearn: 0.3615868\ttotal: 13m 18s\tremaining: 11m 54s\n",
      "528:\tlearn: 0.3601018\ttotal: 13m 20s\tremaining: 11m 52s\n",
      "529:\tlearn: 0.3593883\ttotal: 13m 21s\tremaining: 11m 50s\n",
      "530:\tlearn: 0.3586206\ttotal: 13m 23s\tremaining: 11m 49s\n",
      "531:\tlearn: 0.3577841\ttotal: 13m 24s\tremaining: 11m 47s\n",
      "532:\tlearn: 0.3572835\ttotal: 13m 26s\tremaining: 11m 46s\n",
      "533:\tlearn: 0.3566462\ttotal: 13m 27s\tremaining: 11m 44s\n",
      "534:\tlearn: 0.3557763\ttotal: 13m 28s\tremaining: 11m 43s\n",
      "535:\tlearn: 0.3550128\ttotal: 13m 30s\tremaining: 11m 41s\n",
      "536:\tlearn: 0.3541639\ttotal: 13m 31s\tremaining: 11m 40s\n",
      "537:\tlearn: 0.3533892\ttotal: 13m 33s\tremaining: 11m 38s\n",
      "538:\tlearn: 0.3526331\ttotal: 13m 34s\tremaining: 11m 36s\n",
      "539:\tlearn: 0.3521530\ttotal: 13m 36s\tremaining: 11m 35s\n",
      "540:\tlearn: 0.3514525\ttotal: 13m 37s\tremaining: 11m 33s\n",
      "541:\tlearn: 0.3509353\ttotal: 13m 39s\tremaining: 11m 32s\n",
      "542:\tlearn: 0.3500762\ttotal: 13m 40s\tremaining: 11m 30s\n",
      "543:\tlearn: 0.3494596\ttotal: 13m 42s\tremaining: 11m 29s\n",
      "544:\tlearn: 0.3486612\ttotal: 13m 43s\tremaining: 11m 27s\n",
      "545:\tlearn: 0.3480697\ttotal: 13m 44s\tremaining: 11m 25s\n",
      "546:\tlearn: 0.3472334\ttotal: 13m 46s\tremaining: 11m 24s\n",
      "547:\tlearn: 0.3464641\ttotal: 13m 47s\tremaining: 11m 22s\n",
      "548:\tlearn: 0.3458890\ttotal: 13m 49s\tremaining: 11m 21s\n",
      "549:\tlearn: 0.3451514\ttotal: 13m 50s\tremaining: 11m 19s\n",
      "550:\tlearn: 0.3446954\ttotal: 13m 52s\tremaining: 11m 18s\n",
      "551:\tlearn: 0.3437746\ttotal: 13m 53s\tremaining: 11m 16s\n",
      "552:\tlearn: 0.3431561\ttotal: 13m 55s\tremaining: 11m 15s\n",
      "553:\tlearn: 0.3422290\ttotal: 13m 56s\tremaining: 11m 13s\n",
      "554:\tlearn: 0.3418261\ttotal: 13m 57s\tremaining: 11m 11s\n",
      "555:\tlearn: 0.3411199\ttotal: 13m 59s\tremaining: 11m 10s\n",
      "556:\tlearn: 0.3406766\ttotal: 14m\tremaining: 11m 8s\n",
      "557:\tlearn: 0.3399098\ttotal: 14m 2s\tremaining: 11m 7s\n",
      "558:\tlearn: 0.3392674\ttotal: 14m 3s\tremaining: 11m 5s\n",
      "559:\tlearn: 0.3386274\ttotal: 14m 5s\tremaining: 11m 4s\n",
      "560:\tlearn: 0.3378428\ttotal: 14m 6s\tremaining: 11m 2s\n",
      "561:\tlearn: 0.3373564\ttotal: 14m 8s\tremaining: 11m\n",
      "562:\tlearn: 0.3364163\ttotal: 14m 9s\tremaining: 10m 59s\n",
      "563:\tlearn: 0.3357562\ttotal: 14m 10s\tremaining: 10m 57s\n",
      "564:\tlearn: 0.3349422\ttotal: 14m 12s\tremaining: 10m 56s\n",
      "565:\tlearn: 0.3343042\ttotal: 14m 13s\tremaining: 10m 54s\n",
      "566:\tlearn: 0.3338063\ttotal: 14m 15s\tremaining: 10m 53s\n",
      "567:\tlearn: 0.3330990\ttotal: 14m 16s\tremaining: 10m 51s\n",
      "568:\tlearn: 0.3326640\ttotal: 14m 18s\tremaining: 10m 50s\n",
      "569:\tlearn: 0.3322973\ttotal: 14m 19s\tremaining: 10m 48s\n",
      "570:\tlearn: 0.3318253\ttotal: 14m 21s\tremaining: 10m 46s\n",
      "571:\tlearn: 0.3310623\ttotal: 14m 22s\tremaining: 10m 45s\n",
      "572:\tlearn: 0.3304661\ttotal: 14m 23s\tremaining: 10m 43s\n",
      "573:\tlearn: 0.3298713\ttotal: 14m 25s\tremaining: 10m 42s\n",
      "574:\tlearn: 0.3291757\ttotal: 14m 26s\tremaining: 10m 40s\n",
      "575:\tlearn: 0.3286666\ttotal: 14m 28s\tremaining: 10m 39s\n",
      "576:\tlearn: 0.3279081\ttotal: 14m 29s\tremaining: 10m 37s\n",
      "577:\tlearn: 0.3271712\ttotal: 14m 31s\tremaining: 10m 35s\n",
      "578:\tlearn: 0.3265692\ttotal: 14m 32s\tremaining: 10m 34s\n",
      "579:\tlearn: 0.3259124\ttotal: 14m 34s\tremaining: 10m 32s\n",
      "580:\tlearn: 0.3254288\ttotal: 14m 35s\tremaining: 10m 31s\n",
      "581:\tlearn: 0.3245184\ttotal: 14m 36s\tremaining: 10m 29s\n",
      "582:\tlearn: 0.3239847\ttotal: 14m 38s\tremaining: 10m 28s\n",
      "583:\tlearn: 0.3234488\ttotal: 14m 39s\tremaining: 10m 26s\n",
      "584:\tlearn: 0.3229799\ttotal: 14m 41s\tremaining: 10m 25s\n",
      "585:\tlearn: 0.3225240\ttotal: 14m 42s\tremaining: 10m 23s\n",
      "586:\tlearn: 0.3219330\ttotal: 14m 44s\tremaining: 10m 22s\n",
      "587:\tlearn: 0.3210432\ttotal: 14m 45s\tremaining: 10m 20s\n",
      "588:\tlearn: 0.3202359\ttotal: 14m 47s\tremaining: 10m 19s\n",
      "589:\tlearn: 0.3199158\ttotal: 14m 48s\tremaining: 10m 17s\n",
      "590:\tlearn: 0.3194516\ttotal: 14m 49s\tremaining: 10m 15s\n",
      "591:\tlearn: 0.3189724\ttotal: 14m 51s\tremaining: 10m 14s\n",
      "592:\tlearn: 0.3182209\ttotal: 14m 52s\tremaining: 10m 12s\n",
      "593:\tlearn: 0.3175334\ttotal: 14m 54s\tremaining: 10m 11s\n",
      "594:\tlearn: 0.3168307\ttotal: 14m 55s\tremaining: 10m 9s\n",
      "595:\tlearn: 0.3163847\ttotal: 14m 57s\tremaining: 10m 8s\n",
      "596:\tlearn: 0.3157693\ttotal: 14m 58s\tremaining: 10m 6s\n",
      "597:\tlearn: 0.3151493\ttotal: 15m\tremaining: 10m 5s\n",
      "598:\tlearn: 0.3146433\ttotal: 15m 1s\tremaining: 10m 3s\n",
      "599:\tlearn: 0.3137078\ttotal: 15m 3s\tremaining: 10m 2s\n",
      "600:\tlearn: 0.3128835\ttotal: 15m 4s\tremaining: 10m\n",
      "601:\tlearn: 0.3125260\ttotal: 15m 6s\tremaining: 9m 59s\n",
      "602:\tlearn: 0.3120447\ttotal: 15m 7s\tremaining: 9m 57s\n",
      "603:\tlearn: 0.3117572\ttotal: 15m 8s\tremaining: 9m 55s\n",
      "604:\tlearn: 0.3107700\ttotal: 15m 10s\tremaining: 9m 54s\n",
      "605:\tlearn: 0.3101496\ttotal: 15m 11s\tremaining: 9m 52s\n",
      "606:\tlearn: 0.3097151\ttotal: 15m 13s\tremaining: 9m 51s\n",
      "607:\tlearn: 0.3091379\ttotal: 15m 14s\tremaining: 9m 49s\n",
      "608:\tlearn: 0.3087356\ttotal: 15m 16s\tremaining: 9m 48s\n",
      "609:\tlearn: 0.3080779\ttotal: 15m 17s\tremaining: 9m 46s\n",
      "610:\tlearn: 0.3076529\ttotal: 15m 18s\tremaining: 9m 45s\n",
      "611:\tlearn: 0.3071635\ttotal: 15m 20s\tremaining: 9m 43s\n",
      "612:\tlearn: 0.3063843\ttotal: 15m 21s\tremaining: 9m 41s\n",
      "613:\tlearn: 0.3058582\ttotal: 15m 23s\tremaining: 9m 40s\n",
      "614:\tlearn: 0.3052704\ttotal: 15m 24s\tremaining: 9m 38s\n",
      "615:\tlearn: 0.3047829\ttotal: 15m 26s\tremaining: 9m 37s\n",
      "616:\tlearn: 0.3043886\ttotal: 15m 27s\tremaining: 9m 35s\n",
      "617:\tlearn: 0.3037326\ttotal: 15m 29s\tremaining: 9m 34s\n",
      "618:\tlearn: 0.3029163\ttotal: 15m 30s\tremaining: 9m 32s\n",
      "619:\tlearn: 0.3023662\ttotal: 15m 32s\tremaining: 9m 31s\n",
      "620:\tlearn: 0.3021506\ttotal: 15m 33s\tremaining: 9m 29s\n",
      "621:\tlearn: 0.3013201\ttotal: 15m 34s\tremaining: 9m 28s\n",
      "622:\tlearn: 0.3006678\ttotal: 15m 36s\tremaining: 9m 26s\n",
      "623:\tlearn: 0.3002164\ttotal: 15m 37s\tremaining: 9m 25s\n",
      "624:\tlearn: 0.2999555\ttotal: 15m 39s\tremaining: 9m 23s\n",
      "625:\tlearn: 0.2996647\ttotal: 15m 40s\tremaining: 9m 21s\n",
      "626:\tlearn: 0.2990761\ttotal: 15m 42s\tremaining: 9m 20s\n",
      "627:\tlearn: 0.2983305\ttotal: 15m 43s\tremaining: 9m 18s\n",
      "628:\tlearn: 0.2978476\ttotal: 15m 44s\tremaining: 9m 17s\n",
      "629:\tlearn: 0.2974588\ttotal: 15m 46s\tremaining: 9m 15s\n",
      "630:\tlearn: 0.2967381\ttotal: 15m 47s\tremaining: 9m 14s\n",
      "631:\tlearn: 0.2962053\ttotal: 15m 49s\tremaining: 9m 12s\n",
      "632:\tlearn: 0.2955696\ttotal: 15m 50s\tremaining: 9m 11s\n",
      "633:\tlearn: 0.2949018\ttotal: 15m 52s\tremaining: 9m 9s\n",
      "634:\tlearn: 0.2943976\ttotal: 15m 53s\tremaining: 9m 8s\n",
      "635:\tlearn: 0.2936151\ttotal: 15m 54s\tremaining: 9m 6s\n",
      "636:\tlearn: 0.2930179\ttotal: 15m 56s\tremaining: 9m 5s\n",
      "637:\tlearn: 0.2925171\ttotal: 15m 57s\tremaining: 9m 3s\n",
      "638:\tlearn: 0.2919728\ttotal: 15m 59s\tremaining: 9m 1s\n",
      "639:\tlearn: 0.2913900\ttotal: 16m\tremaining: 9m\n",
      "640:\tlearn: 0.2907853\ttotal: 16m 2s\tremaining: 8m 58s\n",
      "641:\tlearn: 0.2901425\ttotal: 16m 3s\tremaining: 8m 57s\n",
      "642:\tlearn: 0.2898102\ttotal: 16m 5s\tremaining: 8m 55s\n",
      "643:\tlearn: 0.2890393\ttotal: 16m 6s\tremaining: 8m 54s\n",
      "644:\tlearn: 0.2886307\ttotal: 16m 7s\tremaining: 8m 52s\n",
      "645:\tlearn: 0.2882500\ttotal: 16m 9s\tremaining: 8m 51s\n",
      "646:\tlearn: 0.2877179\ttotal: 16m 10s\tremaining: 8m 49s\n",
      "647:\tlearn: 0.2872761\ttotal: 16m 12s\tremaining: 8m 48s\n",
      "648:\tlearn: 0.2869245\ttotal: 16m 13s\tremaining: 8m 46s\n",
      "649:\tlearn: 0.2862702\ttotal: 16m 15s\tremaining: 8m 45s\n",
      "650:\tlearn: 0.2857804\ttotal: 16m 16s\tremaining: 8m 43s\n",
      "651:\tlearn: 0.2855731\ttotal: 16m 17s\tremaining: 8m 41s\n",
      "652:\tlearn: 0.2851150\ttotal: 16m 19s\tremaining: 8m 40s\n",
      "653:\tlearn: 0.2844790\ttotal: 16m 20s\tremaining: 8m 38s\n",
      "654:\tlearn: 0.2840790\ttotal: 16m 22s\tremaining: 8m 37s\n",
      "655:\tlearn: 0.2835045\ttotal: 16m 23s\tremaining: 8m 35s\n",
      "656:\tlearn: 0.2831172\ttotal: 16m 25s\tremaining: 8m 34s\n",
      "657:\tlearn: 0.2824922\ttotal: 16m 26s\tremaining: 8m 32s\n",
      "658:\tlearn: 0.2821468\ttotal: 16m 28s\tremaining: 8m 31s\n",
      "659:\tlearn: 0.2816263\ttotal: 16m 29s\tremaining: 8m 29s\n",
      "660:\tlearn: 0.2811899\ttotal: 16m 30s\tremaining: 8m 28s\n",
      "661:\tlearn: 0.2806566\ttotal: 16m 32s\tremaining: 8m 26s\n",
      "662:\tlearn: 0.2800068\ttotal: 16m 33s\tremaining: 8m 25s\n",
      "663:\tlearn: 0.2796172\ttotal: 16m 35s\tremaining: 8m 23s\n",
      "664:\tlearn: 0.2793353\ttotal: 16m 36s\tremaining: 8m 22s\n",
      "665:\tlearn: 0.2784327\ttotal: 16m 38s\tremaining: 8m 20s\n",
      "666:\tlearn: 0.2781018\ttotal: 16m 39s\tremaining: 8m 19s\n",
      "667:\tlearn: 0.2777038\ttotal: 16m 41s\tremaining: 8m 17s\n",
      "668:\tlearn: 0.2771784\ttotal: 16m 42s\tremaining: 8m 16s\n",
      "669:\tlearn: 0.2766868\ttotal: 16m 43s\tremaining: 8m 14s\n",
      "670:\tlearn: 0.2761746\ttotal: 16m 45s\tremaining: 8m 12s\n",
      "671:\tlearn: 0.2756888\ttotal: 16m 46s\tremaining: 8m 11s\n",
      "672:\tlearn: 0.2749632\ttotal: 16m 48s\tremaining: 8m 9s\n",
      "673:\tlearn: 0.2743059\ttotal: 16m 49s\tremaining: 8m 8s\n",
      "674:\tlearn: 0.2736841\ttotal: 16m 51s\tremaining: 8m 6s\n",
      "675:\tlearn: 0.2730893\ttotal: 16m 52s\tremaining: 8m 5s\n",
      "676:\tlearn: 0.2723391\ttotal: 16m 54s\tremaining: 8m 3s\n",
      "677:\tlearn: 0.2718294\ttotal: 16m 55s\tremaining: 8m 2s\n",
      "678:\tlearn: 0.2715929\ttotal: 16m 57s\tremaining: 8m 1s\n",
      "679:\tlearn: 0.2712983\ttotal: 16m 59s\tremaining: 7m 59s\n",
      "680:\tlearn: 0.2710759\ttotal: 17m\tremaining: 7m 58s\n",
      "681:\tlearn: 0.2706359\ttotal: 17m 2s\tremaining: 7m 56s\n",
      "682:\tlearn: 0.2704371\ttotal: 17m 3s\tremaining: 7m 55s\n",
      "683:\tlearn: 0.2698816\ttotal: 17m 5s\tremaining: 7m 53s\n",
      "684:\tlearn: 0.2693886\ttotal: 17m 7s\tremaining: 7m 52s\n",
      "685:\tlearn: 0.2690115\ttotal: 17m 8s\tremaining: 7m 50s\n",
      "686:\tlearn: 0.2685913\ttotal: 17m 10s\tremaining: 7m 49s\n",
      "687:\tlearn: 0.2683453\ttotal: 17m 11s\tremaining: 7m 47s\n",
      "688:\tlearn: 0.2679059\ttotal: 17m 13s\tremaining: 7m 46s\n",
      "689:\tlearn: 0.2677039\ttotal: 17m 14s\tremaining: 7m 44s\n",
      "690:\tlearn: 0.2673960\ttotal: 17m 16s\tremaining: 7m 43s\n",
      "691:\tlearn: 0.2670764\ttotal: 17m 18s\tremaining: 7m 42s\n",
      "692:\tlearn: 0.2666555\ttotal: 17m 19s\tremaining: 7m 40s\n",
      "693:\tlearn: 0.2660593\ttotal: 17m 21s\tremaining: 7m 39s\n",
      "694:\tlearn: 0.2657671\ttotal: 17m 22s\tremaining: 7m 37s\n",
      "695:\tlearn: 0.2652436\ttotal: 17m 24s\tremaining: 7m 36s\n",
      "696:\tlearn: 0.2647535\ttotal: 17m 26s\tremaining: 7m 34s\n",
      "697:\tlearn: 0.2643467\ttotal: 17m 27s\tremaining: 7m 33s\n",
      "698:\tlearn: 0.2637311\ttotal: 17m 29s\tremaining: 7m 31s\n",
      "699:\tlearn: 0.2632967\ttotal: 17m 30s\tremaining: 7m 30s\n",
      "700:\tlearn: 0.2629265\ttotal: 17m 32s\tremaining: 7m 28s\n",
      "701:\tlearn: 0.2626402\ttotal: 17m 33s\tremaining: 7m 27s\n",
      "702:\tlearn: 0.2620556\ttotal: 17m 35s\tremaining: 7m 25s\n",
      "703:\tlearn: 0.2617281\ttotal: 17m 36s\tremaining: 7m 24s\n",
      "704:\tlearn: 0.2611879\ttotal: 17m 38s\tremaining: 7m 22s\n",
      "705:\tlearn: 0.2609660\ttotal: 17m 39s\tremaining: 7m 21s\n",
      "706:\tlearn: 0.2604039\ttotal: 17m 41s\tremaining: 7m 19s\n",
      "707:\tlearn: 0.2598937\ttotal: 17m 42s\tremaining: 7m 18s\n",
      "708:\tlearn: 0.2595021\ttotal: 17m 43s\tremaining: 7m 16s\n",
      "709:\tlearn: 0.2593120\ttotal: 17m 45s\tremaining: 7m 15s\n",
      "710:\tlearn: 0.2590847\ttotal: 17m 46s\tremaining: 7m 13s\n",
      "711:\tlearn: 0.2586600\ttotal: 17m 48s\tremaining: 7m 12s\n",
      "712:\tlearn: 0.2581696\ttotal: 17m 49s\tremaining: 7m 10s\n",
      "713:\tlearn: 0.2576786\ttotal: 17m 50s\tremaining: 7m 8s\n",
      "714:\tlearn: 0.2571746\ttotal: 17m 52s\tremaining: 7m 7s\n",
      "715:\tlearn: 0.2566204\ttotal: 17m 53s\tremaining: 7m 5s\n",
      "716:\tlearn: 0.2561230\ttotal: 17m 55s\tremaining: 7m 4s\n",
      "717:\tlearn: 0.2554627\ttotal: 17m 56s\tremaining: 7m 2s\n",
      "718:\tlearn: 0.2549618\ttotal: 17m 57s\tremaining: 7m 1s\n",
      "719:\tlearn: 0.2543794\ttotal: 17m 59s\tremaining: 6m 59s\n",
      "720:\tlearn: 0.2540208\ttotal: 18m\tremaining: 6m 58s\n",
      "721:\tlearn: 0.2536420\ttotal: 18m 2s\tremaining: 6m 56s\n",
      "722:\tlearn: 0.2532796\ttotal: 18m 3s\tremaining: 6m 55s\n",
      "723:\tlearn: 0.2527546\ttotal: 18m 4s\tremaining: 6m 53s\n",
      "724:\tlearn: 0.2520387\ttotal: 18m 6s\tremaining: 6m 52s\n",
      "725:\tlearn: 0.2516913\ttotal: 18m 7s\tremaining: 6m 50s\n",
      "726:\tlearn: 0.2510453\ttotal: 18m 9s\tremaining: 6m 49s\n",
      "727:\tlearn: 0.2503447\ttotal: 18m 10s\tremaining: 6m 47s\n",
      "728:\tlearn: 0.2499216\ttotal: 18m 12s\tremaining: 6m 45s\n",
      "729:\tlearn: 0.2495213\ttotal: 18m 13s\tremaining: 6m 44s\n",
      "730:\tlearn: 0.2489151\ttotal: 18m 14s\tremaining: 6m 42s\n",
      "731:\tlearn: 0.2482833\ttotal: 18m 16s\tremaining: 6m 41s\n",
      "732:\tlearn: 0.2479196\ttotal: 18m 17s\tremaining: 6m 39s\n",
      "733:\tlearn: 0.2474797\ttotal: 18m 19s\tremaining: 6m 38s\n",
      "734:\tlearn: 0.2471260\ttotal: 18m 20s\tremaining: 6m 36s\n",
      "735:\tlearn: 0.2468726\ttotal: 18m 21s\tremaining: 6m 35s\n",
      "736:\tlearn: 0.2461038\ttotal: 18m 23s\tremaining: 6m 33s\n",
      "737:\tlearn: 0.2458527\ttotal: 18m 24s\tremaining: 6m 32s\n",
      "738:\tlearn: 0.2455090\ttotal: 18m 26s\tremaining: 6m 30s\n",
      "739:\tlearn: 0.2451288\ttotal: 18m 27s\tremaining: 6m 29s\n",
      "740:\tlearn: 0.2444074\ttotal: 18m 28s\tremaining: 6m 27s\n",
      "741:\tlearn: 0.2440942\ttotal: 18m 30s\tremaining: 6m 26s\n",
      "742:\tlearn: 0.2436465\ttotal: 18m 31s\tremaining: 6m 24s\n",
      "743:\tlearn: 0.2433537\ttotal: 18m 33s\tremaining: 6m 23s\n",
      "744:\tlearn: 0.2429401\ttotal: 18m 34s\tremaining: 6m 21s\n",
      "745:\tlearn: 0.2425773\ttotal: 18m 36s\tremaining: 6m 19s\n",
      "746:\tlearn: 0.2422258\ttotal: 18m 37s\tremaining: 6m 18s\n",
      "747:\tlearn: 0.2419884\ttotal: 18m 38s\tremaining: 6m 16s\n",
      "748:\tlearn: 0.2417192\ttotal: 18m 40s\tremaining: 6m 15s\n",
      "749:\tlearn: 0.2414839\ttotal: 18m 41s\tremaining: 6m 13s\n",
      "750:\tlearn: 0.2411057\ttotal: 18m 42s\tremaining: 6m 12s\n",
      "751:\tlearn: 0.2403343\ttotal: 18m 44s\tremaining: 6m 10s\n",
      "752:\tlearn: 0.2400350\ttotal: 18m 45s\tremaining: 6m 9s\n",
      "753:\tlearn: 0.2396946\ttotal: 18m 47s\tremaining: 6m 7s\n",
      "754:\tlearn: 0.2393113\ttotal: 18m 48s\tremaining: 6m 6s\n",
      "755:\tlearn: 0.2388587\ttotal: 18m 49s\tremaining: 6m 4s\n",
      "756:\tlearn: 0.2385681\ttotal: 18m 51s\tremaining: 6m 3s\n",
      "757:\tlearn: 0.2382240\ttotal: 18m 52s\tremaining: 6m 1s\n",
      "758:\tlearn: 0.2377921\ttotal: 18m 54s\tremaining: 6m\n",
      "759:\tlearn: 0.2374928\ttotal: 18m 55s\tremaining: 5m 58s\n",
      "760:\tlearn: 0.2372525\ttotal: 18m 56s\tremaining: 5m 57s\n",
      "761:\tlearn: 0.2368987\ttotal: 18m 58s\tremaining: 5m 55s\n",
      "762:\tlearn: 0.2363628\ttotal: 18m 59s\tremaining: 5m 54s\n",
      "763:\tlearn: 0.2360059\ttotal: 19m 1s\tremaining: 5m 52s\n",
      "764:\tlearn: 0.2357234\ttotal: 19m 2s\tremaining: 5m 51s\n",
      "765:\tlearn: 0.2353768\ttotal: 19m 4s\tremaining: 5m 49s\n",
      "766:\tlearn: 0.2348963\ttotal: 19m 5s\tremaining: 5m 47s\n",
      "767:\tlearn: 0.2343325\ttotal: 19m 6s\tremaining: 5m 46s\n",
      "768:\tlearn: 0.2339381\ttotal: 19m 8s\tremaining: 5m 44s\n",
      "769:\tlearn: 0.2334970\ttotal: 19m 9s\tremaining: 5m 43s\n",
      "770:\tlearn: 0.2330335\ttotal: 19m 11s\tremaining: 5m 41s\n",
      "771:\tlearn: 0.2327330\ttotal: 19m 12s\tremaining: 5m 40s\n",
      "772:\tlearn: 0.2323827\ttotal: 19m 14s\tremaining: 5m 38s\n",
      "773:\tlearn: 0.2319624\ttotal: 19m 15s\tremaining: 5m 37s\n",
      "774:\tlearn: 0.2315721\ttotal: 19m 16s\tremaining: 5m 35s\n",
      "775:\tlearn: 0.2310380\ttotal: 19m 18s\tremaining: 5m 34s\n",
      "776:\tlearn: 0.2306662\ttotal: 19m 19s\tremaining: 5m 32s\n",
      "777:\tlearn: 0.2302208\ttotal: 19m 21s\tremaining: 5m 31s\n",
      "778:\tlearn: 0.2300909\ttotal: 19m 22s\tremaining: 5m 29s\n",
      "779:\tlearn: 0.2293987\ttotal: 19m 24s\tremaining: 5m 28s\n",
      "780:\tlearn: 0.2292108\ttotal: 19m 25s\tremaining: 5m 26s\n",
      "781:\tlearn: 0.2287426\ttotal: 19m 26s\tremaining: 5m 25s\n",
      "782:\tlearn: 0.2284816\ttotal: 19m 28s\tremaining: 5m 23s\n",
      "783:\tlearn: 0.2281919\ttotal: 19m 29s\tremaining: 5m 22s\n",
      "784:\tlearn: 0.2279051\ttotal: 19m 31s\tremaining: 5m 20s\n",
      "785:\tlearn: 0.2276265\ttotal: 19m 32s\tremaining: 5m 19s\n",
      "786:\tlearn: 0.2271341\ttotal: 19m 33s\tremaining: 5m 17s\n",
      "787:\tlearn: 0.2268806\ttotal: 19m 35s\tremaining: 5m 16s\n",
      "788:\tlearn: 0.2265921\ttotal: 19m 36s\tremaining: 5m 14s\n",
      "789:\tlearn: 0.2260546\ttotal: 19m 38s\tremaining: 5m 13s\n",
      "790:\tlearn: 0.2258726\ttotal: 19m 39s\tremaining: 5m 11s\n",
      "791:\tlearn: 0.2255197\ttotal: 19m 41s\tremaining: 5m 10s\n",
      "792:\tlearn: 0.2249605\ttotal: 19m 42s\tremaining: 5m 8s\n",
      "793:\tlearn: 0.2244352\ttotal: 19m 43s\tremaining: 5m 7s\n",
      "794:\tlearn: 0.2237895\ttotal: 19m 45s\tremaining: 5m 5s\n",
      "795:\tlearn: 0.2232489\ttotal: 19m 46s\tremaining: 5m 4s\n",
      "796:\tlearn: 0.2226427\ttotal: 19m 48s\tremaining: 5m 2s\n",
      "797:\tlearn: 0.2221468\ttotal: 19m 49s\tremaining: 5m 1s\n",
      "798:\tlearn: 0.2215824\ttotal: 19m 50s\tremaining: 4m 59s\n",
      "799:\tlearn: 0.2211804\ttotal: 19m 52s\tremaining: 4m 58s\n",
      "800:\tlearn: 0.2208259\ttotal: 19m 53s\tremaining: 4m 56s\n",
      "801:\tlearn: 0.2204511\ttotal: 19m 55s\tremaining: 4m 55s\n",
      "802:\tlearn: 0.2201955\ttotal: 19m 56s\tremaining: 4m 53s\n",
      "803:\tlearn: 0.2196807\ttotal: 19m 58s\tremaining: 4m 52s\n",
      "804:\tlearn: 0.2193693\ttotal: 19m 59s\tremaining: 4m 50s\n",
      "805:\tlearn: 0.2190832\ttotal: 20m\tremaining: 4m 49s\n",
      "806:\tlearn: 0.2187884\ttotal: 20m 2s\tremaining: 4m 47s\n",
      "807:\tlearn: 0.2184551\ttotal: 20m 3s\tremaining: 4m 46s\n",
      "808:\tlearn: 0.2180490\ttotal: 20m 4s\tremaining: 4m 44s\n",
      "809:\tlearn: 0.2178642\ttotal: 20m 6s\tremaining: 4m 43s\n",
      "810:\tlearn: 0.2177147\ttotal: 20m 7s\tremaining: 4m 41s\n",
      "811:\tlearn: 0.2174148\ttotal: 20m 9s\tremaining: 4m 40s\n",
      "812:\tlearn: 0.2171550\ttotal: 20m 10s\tremaining: 4m 38s\n",
      "813:\tlearn: 0.2167763\ttotal: 20m 12s\tremaining: 4m 36s\n",
      "814:\tlearn: 0.2162042\ttotal: 20m 13s\tremaining: 4m 35s\n",
      "815:\tlearn: 0.2157540\ttotal: 20m 15s\tremaining: 4m 33s\n",
      "816:\tlearn: 0.2154786\ttotal: 20m 16s\tremaining: 4m 32s\n",
      "817:\tlearn: 0.2152289\ttotal: 20m 17s\tremaining: 4m 30s\n",
      "818:\tlearn: 0.2147582\ttotal: 20m 19s\tremaining: 4m 29s\n",
      "819:\tlearn: 0.2145377\ttotal: 20m 20s\tremaining: 4m 27s\n",
      "820:\tlearn: 0.2143373\ttotal: 20m 22s\tremaining: 4m 26s\n",
      "821:\tlearn: 0.2139488\ttotal: 20m 23s\tremaining: 4m 24s\n",
      "822:\tlearn: 0.2136799\ttotal: 20m 24s\tremaining: 4m 23s\n",
      "823:\tlearn: 0.2133204\ttotal: 20m 26s\tremaining: 4m 21s\n",
      "824:\tlearn: 0.2129817\ttotal: 20m 27s\tremaining: 4m 20s\n",
      "825:\tlearn: 0.2124370\ttotal: 20m 29s\tremaining: 4m 18s\n",
      "826:\tlearn: 0.2120696\ttotal: 20m 30s\tremaining: 4m 17s\n",
      "827:\tlearn: 0.2116924\ttotal: 20m 32s\tremaining: 4m 15s\n",
      "828:\tlearn: 0.2114805\ttotal: 20m 33s\tremaining: 4m 14s\n",
      "829:\tlearn: 0.2110953\ttotal: 20m 34s\tremaining: 4m 12s\n",
      "830:\tlearn: 0.2106785\ttotal: 20m 36s\tremaining: 4m 11s\n",
      "831:\tlearn: 0.2102677\ttotal: 20m 37s\tremaining: 4m 9s\n",
      "832:\tlearn: 0.2098744\ttotal: 20m 39s\tremaining: 4m 8s\n",
      "833:\tlearn: 0.2094526\ttotal: 20m 40s\tremaining: 4m 6s\n",
      "834:\tlearn: 0.2090371\ttotal: 20m 41s\tremaining: 4m 5s\n",
      "835:\tlearn: 0.2086913\ttotal: 20m 43s\tremaining: 4m 3s\n",
      "836:\tlearn: 0.2083854\ttotal: 20m 44s\tremaining: 4m 2s\n",
      "837:\tlearn: 0.2078516\ttotal: 20m 46s\tremaining: 4m\n",
      "838:\tlearn: 0.2075408\ttotal: 20m 47s\tremaining: 3m 59s\n",
      "839:\tlearn: 0.2072459\ttotal: 20m 48s\tremaining: 3m 57s\n",
      "840:\tlearn: 0.2070327\ttotal: 20m 50s\tremaining: 3m 56s\n",
      "841:\tlearn: 0.2065793\ttotal: 20m 51s\tremaining: 3m 54s\n",
      "842:\tlearn: 0.2061953\ttotal: 20m 53s\tremaining: 3m 53s\n",
      "843:\tlearn: 0.2057195\ttotal: 20m 54s\tremaining: 3m 51s\n",
      "844:\tlearn: 0.2053907\ttotal: 20m 56s\tremaining: 3m 50s\n",
      "845:\tlearn: 0.2050726\ttotal: 20m 57s\tremaining: 3m 48s\n",
      "846:\tlearn: 0.2044882\ttotal: 20m 58s\tremaining: 3m 47s\n",
      "847:\tlearn: 0.2043208\ttotal: 21m\tremaining: 3m 45s\n",
      "848:\tlearn: 0.2040108\ttotal: 21m 1s\tremaining: 3m 44s\n",
      "849:\tlearn: 0.2037124\ttotal: 21m 3s\tremaining: 3m 42s\n",
      "850:\tlearn: 0.2035223\ttotal: 21m 4s\tremaining: 3m 41s\n",
      "851:\tlearn: 0.2030033\ttotal: 21m 6s\tremaining: 3m 39s\n",
      "852:\tlearn: 0.2027623\ttotal: 21m 7s\tremaining: 3m 38s\n",
      "853:\tlearn: 0.2024465\ttotal: 21m 8s\tremaining: 3m 36s\n",
      "854:\tlearn: 0.2019921\ttotal: 21m 10s\tremaining: 3m 35s\n",
      "855:\tlearn: 0.2015050\ttotal: 21m 11s\tremaining: 3m 33s\n",
      "856:\tlearn: 0.2012220\ttotal: 21m 13s\tremaining: 3m 32s\n",
      "857:\tlearn: 0.2008465\ttotal: 21m 14s\tremaining: 3m 30s\n",
      "858:\tlearn: 0.2003732\ttotal: 21m 15s\tremaining: 3m 29s\n",
      "859:\tlearn: 0.2001686\ttotal: 21m 17s\tremaining: 3m 27s\n",
      "860:\tlearn: 0.1999493\ttotal: 21m 18s\tremaining: 3m 26s\n",
      "861:\tlearn: 0.1997422\ttotal: 21m 20s\tremaining: 3m 24s\n",
      "862:\tlearn: 0.1992545\ttotal: 21m 21s\tremaining: 3m 23s\n",
      "863:\tlearn: 0.1989388\ttotal: 21m 23s\tremaining: 3m 21s\n",
      "864:\tlearn: 0.1986224\ttotal: 21m 24s\tremaining: 3m 20s\n",
      "865:\tlearn: 0.1982495\ttotal: 21m 25s\tremaining: 3m 18s\n",
      "866:\tlearn: 0.1980139\ttotal: 21m 27s\tremaining: 3m 17s\n",
      "867:\tlearn: 0.1976342\ttotal: 21m 28s\tremaining: 3m 15s\n",
      "868:\tlearn: 0.1970588\ttotal: 21m 30s\tremaining: 3m 14s\n",
      "869:\tlearn: 0.1967982\ttotal: 21m 31s\tremaining: 3m 12s\n",
      "870:\tlearn: 0.1964872\ttotal: 21m 33s\tremaining: 3m 11s\n",
      "871:\tlearn: 0.1962714\ttotal: 21m 34s\tremaining: 3m 10s\n",
      "872:\tlearn: 0.1960233\ttotal: 21m 35s\tremaining: 3m 8s\n",
      "873:\tlearn: 0.1958758\ttotal: 21m 37s\tremaining: 3m 7s\n",
      "874:\tlearn: 0.1956467\ttotal: 21m 38s\tremaining: 3m 5s\n",
      "875:\tlearn: 0.1951730\ttotal: 21m 40s\tremaining: 3m 4s\n",
      "876:\tlearn: 0.1949459\ttotal: 21m 41s\tremaining: 3m 2s\n",
      "877:\tlearn: 0.1946652\ttotal: 21m 42s\tremaining: 3m 1s\n",
      "878:\tlearn: 0.1941595\ttotal: 21m 44s\tremaining: 2m 59s\n",
      "879:\tlearn: 0.1938405\ttotal: 21m 45s\tremaining: 2m 58s\n",
      "880:\tlearn: 0.1936707\ttotal: 21m 47s\tremaining: 2m 56s\n",
      "881:\tlearn: 0.1932634\ttotal: 21m 48s\tremaining: 2m 55s\n",
      "882:\tlearn: 0.1930179\ttotal: 21m 49s\tremaining: 2m 53s\n",
      "883:\tlearn: 0.1928155\ttotal: 21m 51s\tremaining: 2m 52s\n",
      "884:\tlearn: 0.1925082\ttotal: 21m 52s\tremaining: 2m 50s\n",
      "885:\tlearn: 0.1921011\ttotal: 21m 54s\tremaining: 2m 49s\n",
      "886:\tlearn: 0.1918287\ttotal: 21m 55s\tremaining: 2m 47s\n",
      "887:\tlearn: 0.1915512\ttotal: 21m 56s\tremaining: 2m 46s\n",
      "888:\tlearn: 0.1912984\ttotal: 21m 58s\tremaining: 2m 44s\n",
      "889:\tlearn: 0.1910047\ttotal: 21m 59s\tremaining: 2m 43s\n",
      "890:\tlearn: 0.1905600\ttotal: 22m 1s\tremaining: 2m 41s\n",
      "891:\tlearn: 0.1901135\ttotal: 22m 2s\tremaining: 2m 40s\n",
      "892:\tlearn: 0.1898271\ttotal: 22m 4s\tremaining: 2m 38s\n",
      "893:\tlearn: 0.1894242\ttotal: 22m 5s\tremaining: 2m 37s\n",
      "894:\tlearn: 0.1891524\ttotal: 22m 7s\tremaining: 2m 35s\n",
      "895:\tlearn: 0.1889083\ttotal: 22m 8s\tremaining: 2m 34s\n",
      "896:\tlearn: 0.1886005\ttotal: 22m 9s\tremaining: 2m 32s\n",
      "897:\tlearn: 0.1883464\ttotal: 22m 11s\tremaining: 2m 31s\n",
      "898:\tlearn: 0.1879134\ttotal: 22m 12s\tremaining: 2m 29s\n",
      "899:\tlearn: 0.1873695\ttotal: 22m 14s\tremaining: 2m 28s\n",
      "900:\tlearn: 0.1870834\ttotal: 22m 15s\tremaining: 2m 26s\n",
      "901:\tlearn: 0.1867592\ttotal: 22m 16s\tremaining: 2m 25s\n",
      "902:\tlearn: 0.1864518\ttotal: 22m 18s\tremaining: 2m 23s\n",
      "903:\tlearn: 0.1862378\ttotal: 22m 19s\tremaining: 2m 22s\n",
      "904:\tlearn: 0.1858959\ttotal: 22m 21s\tremaining: 2m 20s\n",
      "905:\tlearn: 0.1856940\ttotal: 22m 22s\tremaining: 2m 19s\n",
      "906:\tlearn: 0.1854779\ttotal: 22m 23s\tremaining: 2m 17s\n",
      "907:\tlearn: 0.1851911\ttotal: 22m 25s\tremaining: 2m 16s\n",
      "908:\tlearn: 0.1847812\ttotal: 22m 26s\tremaining: 2m 14s\n",
      "909:\tlearn: 0.1843103\ttotal: 22m 28s\tremaining: 2m 13s\n",
      "910:\tlearn: 0.1840902\ttotal: 22m 29s\tremaining: 2m 11s\n",
      "911:\tlearn: 0.1838346\ttotal: 22m 31s\tremaining: 2m 10s\n",
      "912:\tlearn: 0.1834770\ttotal: 22m 32s\tremaining: 2m 8s\n",
      "913:\tlearn: 0.1831539\ttotal: 22m 34s\tremaining: 2m 7s\n",
      "914:\tlearn: 0.1827729\ttotal: 22m 35s\tremaining: 2m 5s\n",
      "915:\tlearn: 0.1823678\ttotal: 22m 36s\tremaining: 2m 4s\n",
      "916:\tlearn: 0.1820757\ttotal: 22m 38s\tremaining: 2m 2s\n",
      "917:\tlearn: 0.1815492\ttotal: 22m 39s\tremaining: 2m 1s\n",
      "918:\tlearn: 0.1811997\ttotal: 22m 41s\tremaining: 1m 59s\n",
      "919:\tlearn: 0.1809292\ttotal: 22m 42s\tremaining: 1m 58s\n",
      "920:\tlearn: 0.1807188\ttotal: 22m 43s\tremaining: 1m 56s\n",
      "921:\tlearn: 0.1804974\ttotal: 22m 45s\tremaining: 1m 55s\n",
      "922:\tlearn: 0.1803914\ttotal: 22m 46s\tremaining: 1m 54s\n",
      "923:\tlearn: 0.1800500\ttotal: 22m 48s\tremaining: 1m 52s\n",
      "924:\tlearn: 0.1798896\ttotal: 22m 49s\tremaining: 1m 51s\n",
      "925:\tlearn: 0.1796001\ttotal: 22m 50s\tremaining: 1m 49s\n",
      "926:\tlearn: 0.1794028\ttotal: 22m 52s\tremaining: 1m 48s\n",
      "927:\tlearn: 0.1790859\ttotal: 22m 53s\tremaining: 1m 46s\n",
      "928:\tlearn: 0.1788256\ttotal: 22m 55s\tremaining: 1m 45s\n",
      "929:\tlearn: 0.1785813\ttotal: 22m 56s\tremaining: 1m 43s\n",
      "930:\tlearn: 0.1782743\ttotal: 22m 58s\tremaining: 1m 42s\n",
      "931:\tlearn: 0.1780122\ttotal: 22m 59s\tremaining: 1m 40s\n",
      "932:\tlearn: 0.1776187\ttotal: 23m\tremaining: 1m 39s\n",
      "933:\tlearn: 0.1772327\ttotal: 23m 2s\tremaining: 1m 37s\n",
      "934:\tlearn: 0.1768909\ttotal: 23m 3s\tremaining: 1m 36s\n",
      "935:\tlearn: 0.1766842\ttotal: 23m 5s\tremaining: 1m 34s\n",
      "936:\tlearn: 0.1764382\ttotal: 23m 6s\tremaining: 1m 33s\n",
      "937:\tlearn: 0.1761899\ttotal: 23m 8s\tremaining: 1m 31s\n",
      "938:\tlearn: 0.1758328\ttotal: 23m 9s\tremaining: 1m 30s\n",
      "939:\tlearn: 0.1753871\ttotal: 23m 10s\tremaining: 1m 28s\n",
      "940:\tlearn: 0.1752332\ttotal: 23m 12s\tremaining: 1m 27s\n",
      "941:\tlearn: 0.1748765\ttotal: 23m 13s\tremaining: 1m 25s\n",
      "942:\tlearn: 0.1746335\ttotal: 23m 15s\tremaining: 1m 24s\n",
      "943:\tlearn: 0.1743837\ttotal: 23m 16s\tremaining: 1m 22s\n",
      "944:\tlearn: 0.1739817\ttotal: 23m 17s\tremaining: 1m 21s\n",
      "945:\tlearn: 0.1736416\ttotal: 23m 19s\tremaining: 1m 19s\n",
      "946:\tlearn: 0.1732546\ttotal: 23m 20s\tremaining: 1m 18s\n",
      "947:\tlearn: 0.1729843\ttotal: 23m 22s\tremaining: 1m 16s\n",
      "948:\tlearn: 0.1727251\ttotal: 23m 23s\tremaining: 1m 15s\n",
      "949:\tlearn: 0.1723263\ttotal: 23m 25s\tremaining: 1m 13s\n",
      "950:\tlearn: 0.1721110\ttotal: 23m 26s\tremaining: 1m 12s\n",
      "951:\tlearn: 0.1717730\ttotal: 23m 27s\tremaining: 1m 10s\n",
      "952:\tlearn: 0.1714369\ttotal: 23m 29s\tremaining: 1m 9s\n",
      "953:\tlearn: 0.1710097\ttotal: 23m 30s\tremaining: 1m 8s\n",
      "954:\tlearn: 0.1705962\ttotal: 23m 32s\tremaining: 1m 6s\n",
      "955:\tlearn: 0.1701697\ttotal: 23m 33s\tremaining: 1m 5s\n",
      "956:\tlearn: 0.1698165\ttotal: 23m 35s\tremaining: 1m 3s\n",
      "957:\tlearn: 0.1695987\ttotal: 23m 36s\tremaining: 1m 2s\n",
      "958:\tlearn: 0.1692665\ttotal: 23m 37s\tremaining: 1m\n",
      "959:\tlearn: 0.1690716\ttotal: 23m 39s\tremaining: 59.1s\n",
      "960:\tlearn: 0.1686732\ttotal: 23m 40s\tremaining: 57.7s\n",
      "961:\tlearn: 0.1684949\ttotal: 23m 42s\tremaining: 56.2s\n",
      "962:\tlearn: 0.1682661\ttotal: 23m 43s\tremaining: 54.7s\n",
      "963:\tlearn: 0.1679962\ttotal: 23m 45s\tremaining: 53.2s\n",
      "964:\tlearn: 0.1677351\ttotal: 23m 46s\tremaining: 51.7s\n",
      "965:\tlearn: 0.1674954\ttotal: 23m 48s\tremaining: 50.3s\n",
      "966:\tlearn: 0.1673065\ttotal: 23m 49s\tremaining: 48.8s\n",
      "967:\tlearn: 0.1671485\ttotal: 23m 51s\tremaining: 47.3s\n",
      "968:\tlearn: 0.1669136\ttotal: 23m 52s\tremaining: 45.8s\n",
      "969:\tlearn: 0.1667037\ttotal: 23m 53s\tremaining: 44.3s\n",
      "970:\tlearn: 0.1663858\ttotal: 23m 55s\tremaining: 42.9s\n",
      "971:\tlearn: 0.1662270\ttotal: 23m 56s\tremaining: 41.4s\n",
      "972:\tlearn: 0.1660297\ttotal: 23m 58s\tremaining: 39.9s\n",
      "973:\tlearn: 0.1657027\ttotal: 23m 59s\tremaining: 38.4s\n",
      "974:\tlearn: 0.1653422\ttotal: 24m 1s\tremaining: 37s\n",
      "975:\tlearn: 0.1650501\ttotal: 24m 2s\tremaining: 35.5s\n",
      "976:\tlearn: 0.1647093\ttotal: 24m 4s\tremaining: 34s\n",
      "977:\tlearn: 0.1643794\ttotal: 24m 5s\tremaining: 32.5s\n",
      "978:\tlearn: 0.1641330\ttotal: 24m 7s\tremaining: 31s\n",
      "979:\tlearn: 0.1639409\ttotal: 24m 8s\tremaining: 29.6s\n",
      "980:\tlearn: 0.1636417\ttotal: 24m 10s\tremaining: 28.1s\n",
      "981:\tlearn: 0.1633928\ttotal: 24m 11s\tremaining: 26.6s\n",
      "982:\tlearn: 0.1631922\ttotal: 24m 12s\tremaining: 25.1s\n",
      "983:\tlearn: 0.1628566\ttotal: 24m 14s\tremaining: 23.6s\n",
      "984:\tlearn: 0.1625718\ttotal: 24m 15s\tremaining: 22.2s\n",
      "985:\tlearn: 0.1622883\ttotal: 24m 17s\tremaining: 20.7s\n",
      "986:\tlearn: 0.1619040\ttotal: 24m 18s\tremaining: 19.2s\n",
      "987:\tlearn: 0.1616152\ttotal: 24m 20s\tremaining: 17.7s\n",
      "988:\tlearn: 0.1615136\ttotal: 24m 21s\tremaining: 16.3s\n",
      "989:\tlearn: 0.1613551\ttotal: 24m 22s\tremaining: 14.8s\n",
      "990:\tlearn: 0.1610826\ttotal: 24m 24s\tremaining: 13.3s\n",
      "991:\tlearn: 0.1607987\ttotal: 24m 25s\tremaining: 11.8s\n",
      "992:\tlearn: 0.1605115\ttotal: 24m 27s\tremaining: 10.3s\n",
      "993:\tlearn: 0.1602629\ttotal: 24m 28s\tremaining: 8.86s\n",
      "994:\tlearn: 0.1599349\ttotal: 24m 29s\tremaining: 7.39s\n",
      "995:\tlearn: 0.1598548\ttotal: 24m 31s\tremaining: 5.91s\n",
      "996:\tlearn: 0.1596532\ttotal: 24m 32s\tremaining: 4.43s\n",
      "997:\tlearn: 0.1594225\ttotal: 24m 34s\tremaining: 2.95s\n",
      "998:\tlearn: 0.1591370\ttotal: 24m 36s\tremaining: 1.48s\n",
      "999:\tlearn: 0.1589485\ttotal: 24m 37s\tremaining: 0us\n",
      "MSE: 17.645714285714284\n",
      "Accuracy: 0.4942857142857143\n",
      "F-score: 0.4106702110213185\n",
      "ROC-AUC: 0.6802093630525532\n"
     ]
    }
   ],
   "source": [
    "cbc = CatBoostClassifier()\n",
    "\n",
    "cbc.fit(X_train, y_train)\n",
    "preds_class = cbc.predict(X_test)\n",
    "print_metrics(preds_class, y_test, cbc.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "MSE: 18.44857142857143\n",
      "Accuracy: 0.47714285714285715\n",
      "F-score: 0.43337334538668676\n",
      "ROC-AUC: 0.7064471626202647\n",
      "\n",
      "Train:\n",
      "MSE: 9.060991105463787\n",
      "Accuracy: 0.7179161372299873\n",
      "F-score: 0.6944621806993498\n",
      "ROC-AUC: 0.9271285214180605\n"
     ]
    }
   ],
   "source": [
    "linSVM = SVC(\n",
    "             C=0.1, \n",
    "             kernel=\"linear\", \n",
    "             degree=3, \n",
    "             gamma=\"scale\", \n",
    "             coef0=0, \n",
    "             shrinking=True, \n",
    "             probability=True, \n",
    "             tol=0.001, \n",
    "             cache_size=200, \n",
    "             class_weight=None, \n",
    "             verbose=False, \n",
    "             # max_iter: Int = ..., \n",
    "             decision_function_shape=\"ovr\", \n",
    "             break_ties=False, \n",
    "             random_state=42\n",
    ")\n",
    "\n",
    "linSVM.fit(X=X_train, y=y_train)\n",
    "\n",
    "print(\"Test:\")\n",
    "print_metrics(linSVM.predict(X_test), y_test, linSVM.predict_proba(X_test))\n",
    "print(\"\\nTrain:\")\n",
    "print_metrics(linSVM.predict(X_train), y_train, linSVM.predict_proba(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=4)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: SVC</label><div class=\"sk-toggleable__content fitted\"><pre>SVC(random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             verbose=4)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid = GridSearchCV(estimator=svm, \n",
    "                        param_grid=parameters, \n",
    "                        scoring=None, \n",
    "                        refit=True, \n",
    "                        verbose=4, \n",
    "                        pre_dispatch=\"2*n_jobs\", \n",
    "                        return_train_score=False, \n",
    "                        cv=5, \n",
    "                        n_jobs=-1)\n",
    "svm_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'poly'}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
